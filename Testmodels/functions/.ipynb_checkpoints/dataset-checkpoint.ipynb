{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional section can be used for generation of present/future pairs\n",
    "def generate_offset_snapshot_list(trajectory_list, offset):\n",
    "    # if this function is called with offset 0, present and future trajectory list are the same\n",
    "    # as the trajectory_list and are therefore returned like this without any calculation\n",
    "    if offset == 0:\n",
    "        return trajectory_list, trajectory_list\n",
    "    # Takes in a list or np.array of trajectories and an offset value and generates two np.arrays with respective new versions\n",
    "    # of the trajectories. \n",
    "    # present_trajectory_list contains all snapshots of the trajectories excluding\n",
    "    # the last n (speficified by offset) of each.\n",
    "    # future_trajectory_list contains all snapshots of the trajectories excluding\n",
    "    # the first n (specified by offset) of each.\n",
    "    # Consequently the both lists can be used as input and desired output of an autoencoder to\n",
    "    # train for future predictive variables.\n",
    "    past_trajectory_list = np.array([trajectory[:-offset] for trajectory in trajectory_list])  \n",
    "    #truncated_present_trajectory_list = \n",
    "    trajectory_list = np.array([trajectory[offset:] for trajectory in trajectory_list])\n",
    "    return past_trajectory_list, trajectory_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snapshot_label_and_weight_list(trajectory_list, trajectory_label_list, offset = 0, progress_label = False):\n",
    "    # takes in a list of trajectories and corresponding labels and generates concatenated lists of snapshots, \n",
    "    # snapshot label and snapshot progress labels\n",
    "    # can be used for present/future trajcetory lists by use or offset (same as used for generation of the list)\n",
    "    # and future = True for the future trajectory list\n",
    "    snapshot_list = []\n",
    "    snapshot_label_list = []\n",
    "    snapshot_weight_list = []\n",
    "#    len_AA = sum([1 for x in trajectory_label_list if x == 0.0])\n",
    "#    len_AB = sum([1 for x in trajectory_label_list if x == 0.5])\n",
    "#    len_BB = len(trajectory_label_list) - len_AA - len_AB\n",
    "    len_AA = sum([len(trajectory_list[x]) for x in range(len(trajectory_label_list)) \\\n",
    "                  if trajectory_label_list[x] == -1.0])\n",
    "    len_AB = sum([len(trajectory_list[x]) for x in range(len(trajectory_label_list)) \\\n",
    "                  if trajectory_label_list[x] == -0.5])\n",
    "    len_BA = sum([len(trajectory_list[x]) for x in range(len(trajectory_label_list)) \\\n",
    "                  if trajectory_label_list[x] == 0.5])\n",
    "    len_BB = sum([len(trajectory_list[x]) for x in range(len(trajectory_label_list)) \\\n",
    "                  if trajectory_label_list[x] == 1.0])\n",
    "\n",
    "    reciprocal_len_AA = 1.0/len_AA\n",
    "    reciprocal_len_AB = 1.0/len_AB\n",
    "    reciprocal_len_BA = 1.0/len_BA\n",
    "    reciprocal_len_BB = 1.0/len_BB\n",
    "    print(len_AA, len_AB, len_BA, len_BB)\n",
    "    for trajectory_nr in range(len(trajectory_list)):\n",
    "        trajectory = trajectory_list[trajectory_nr]\n",
    "        trajectory_label = trajectory_label_list[trajectory_nr]\n",
    "        for snapshot_nr in range(len(trajectory)):\n",
    "            snapshot_list.append(trajectory[snapshot_nr])\n",
    "            \"\"\"\n",
    "            Assigns the label and weight for each of the snapshots.\n",
    "            For AA and BB paths the label is set to 0 or 1 respectively, \n",
    "            and the weight set to the corresponding value for this type of path.\n",
    "            If it is a transition path the corresponding weight is assigned to the snapshot,\n",
    "            and depending on whether progress_label is true or not either the label copied\n",
    "            or recalculated based on how far the path has gotten.\n",
    "            \"\"\"\n",
    "            # Calculates the progress along the path for AB paths. If the path label is 1 or 0,\n",
    "            # all snapshot are assigned the same label. If the path label is different (e.g. 0.5),\n",
    "            # indicating a sucessfull transition a progress along the snapshots is calculated based on\n",
    "            # the position within the trajectory and the total trajectory length.\n",
    "            # For present/future lists, the offset needs to be taken into account in the denominator\n",
    "            # If the dataset is a future variant of an offset trajectory list the progress label \n",
    "            # needs to additionally take the offset into account in the nominator.\n",
    "            if trajectory_label == -1.0:\n",
    "                snapshot_weight_list.append(reciprocal_len_AA*LABEL_AA_weight_factor)\n",
    "                snapshot_label_list.append(-1.0)\n",
    "#                snapshot_label_list.append(trajectory_label)\n",
    "            elif trajectory_label == 1.0:\n",
    "                snapshot_weight_list.append(reciprocal_len_BB*LABEL_BB_weight_factor)\n",
    "                snapshot_label_list.append(1.0)\n",
    "            else:\n",
    "                snapshot_weight_list.append(reciprocal_len_AB*LABEL_AB_weight_factor \\\n",
    "                                          + reciprocal_len_BA*LABEL_BA_weight_factor)\n",
    "                # leaving out \"Future == True\" from prior versions of the code\n",
    "                # means that the snapshot_label_list of the past version will be incorrect\n",
    "                # since it is not used, however, this should not pose a problem\n",
    "\n",
    "                # if the path is an AB path, the progress label counts upwards\n",
    "                # if it is a BA path it counts down\n",
    "                if trajectory_label == -0.5:\n",
    "#                    snapshot_weight_list.append(reciprocal_len_AB*LABEL_AB_weight_factor)\n",
    "                    if progress_label == False:\n",
    "                        snapshot_label_list.append(0.0)\n",
    "                    else:\n",
    "                        snapshot_label_list.append((snapshot_nr + offset)\\\n",
    "                                    /(len(trajectory) - 1.0 + offset))\n",
    "                elif trajectory_label == 0.5:\n",
    "#                    snapshot_weight_list.append(reciprocal_len_BA*LABEL_BA_weight_factor)\n",
    "                    if progress_label == False:\n",
    "                        snapshot_label_list.append(0.0)\n",
    "                    else:\n",
    "                        snapshot_label_list.append((len(trajectory)\\\n",
    "                                    -(snapshot_nr + offset + 1))/(len(trajectory) + offset - 1))\n",
    "\n",
    "    return np.array(snapshot_list), np.array(snapshot_label_list), np.array(snapshot_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(snapshot_list, lower_bound, upper_bound):\n",
    "    \"\"\"Sets the values of a snapshopt that lie outside of the bounds to that \n",
    "    bound while leaving the other values unchanged.\n",
    "    Initially transposes the snapshot_list to a column list\n",
    "    For each column, it iterates over all entries and compares them to the \n",
    "    lower or upper bound of that column. If they are lower or higher, they are changed to\n",
    "    the value of that bound.\n",
    "    Returns the transpose of the column list, thereby giving the cleaned snapshot_list.\n",
    "    \"\"\"\n",
    "    \n",
    "    column_list = np.transpose(snapshot_list)\n",
    "    column_list = [[min(upper_bound[col_nr],max(lower_bound[col_nr],entry)) \\\n",
    "                                for entry in column_list[col_nr]] \\\n",
    "                                for col_nr in range(len(lower_bound))]\n",
    "    return np.transpose(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_snapshots(snapshot_list, mean, std):\n",
    "    \"\"\"Normalizes the snapshot_list by substracting the mean and dividing by the standard deviation.\"\"\"\n",
    "    return (snapshot_list - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_train_test_split(trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False):\n",
    "    assert isinstance(split_ratio, float), \"Split ratio needs to be a float between 0.0 and 1.0\"\n",
    "    past_trajectory_list, trajectory_list = generate_offset_snapshot_list(trajectory_list, offset)\n",
    "    past_snapshot_list, _, _ \\\n",
    "            = get_snapshot_label_and_weight_list( \\\n",
    "            past_trajectory_list, trajectory_label_list, offset, \\\n",
    "            progress_label = progress_label)\n",
    "    snapshot_list, snapshot_label_list, snapshot_weight_list \\\n",
    "            = get_snapshot_label_and_weight_list( \\\n",
    "            trajectory_list, trajectory_label_list, offset, \\\n",
    "            progress_label = progress_label)\n",
    "    past_snapshot_list, snapshot_list, snapshot_label_list, snapshot_weight_list \\\n",
    "            = shuffle(past_snapshot_list, snapshot_list, snapshot_label_list, \\\n",
    "            snapshot_weight_list)\n",
    "    \n",
    "    # could consider removing outliers here, but normialization and bounds are calculated\n",
    "    # based on the training set and therefore do not exist before the split\n",
    "    \n",
    "    train_size = int(len(snapshot_label_list) * split_ratio)\n",
    "    \n",
    "    train_past_snapshot_list = past_snapshot_list[:train_size].copy()\n",
    "    test_past_snapshot_list = past_snapshot_list[train_size:].copy()\n",
    "    train_snapshot_list = snapshot_list[:train_size].copy()\n",
    "    test_snapshot_list = snapshot_list[train_size:].copy()\n",
    "    train_snapshot_label_list = snapshot_label_list[:train_size].copy()\n",
    "    test_snapshot_label_list = snapshot_label_list[train_size:].copy()    \n",
    "    train_snapshot_weight_list = snapshot_weight_list[:train_size].copy()\n",
    "    test_snapshot_weight_list = snapshot_weight_list[train_size:].copy()\n",
    "\n",
    "    # calculates the lower and upper bound for the dataset according to the OUTLIER_CUTOFF\n",
    "    lower_bound = np.percentile(train_past_snapshot_list, 100*OUTLIER_CUTOFF, axis = 0)\n",
    "    upper_bound = np.percentile(train_past_snapshot_list, 100*(1-OUTLIER_CUTOFF), axis = 0)\n",
    "\n",
    "    # removes outliers\n",
    "    train_past_snapshot_list = remove_outliers(train_past_snapshot_list, lower_bound, upper_bound)\n",
    "    test_past_snapshot_list = remove_outliers(test_past_snapshot_list, lower_bound, upper_bound)\n",
    "    train_snapshot_list = remove_outliers(train_snapshot_list, lower_bound, upper_bound)\n",
    "    test_snapshot_list = remove_outliers(test_snapshot_list, lower_bound, upper_bound)\n",
    "\n",
    "    # Calculate mean and std of the test snapshots\n",
    "    train_mean = np.mean(train_snapshot_list, axis = 0)\n",
    "    train_std = np.std(train_snapshot_list, axis = 0)\n",
    "    \n",
    "    # Normalize the data\n",
    "    train_past_snapshot_list = normalize_snapshots(train_past_snapshot_list, train_mean, train_std)\n",
    "    test_past_snapshot_list = normalize_snapshots(test_past_snapshot_list, train_mean, train_std)\n",
    "    train_snapshot_list = normalize_snapshots(train_snapshot_list, train_mean, train_std)\n",
    "    test_snapshot_list = normalize_snapshots(test_snapshot_list, train_mean, train_std)\n",
    "\n",
    "    return train_past_snapshot_list, train_snapshot_list, \\\n",
    "            train_snapshot_label_list, train_snapshot_weight_list, \\\n",
    "            test_past_snapshot_list, test_snapshot_list, \\\n",
    "            test_snapshot_label_list, test_snapshot_weight_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds(trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False):\n",
    "    \"\"\"Insert docstring\"\"\"\n",
    "    train_past_snapshot_list, train_snapshot_list, \\\n",
    "    train_snapshot_label_list, train_snapshot_weight_list, \\\n",
    "    test_past_snapshot_list, test_snapshot_list, \\\n",
    "    test_snapshot_label_list, test_snapshot_weight_list \\\n",
    "        = shuffled_train_test_split(trajectory_list, \\\n",
    "        trajectory_label_list, split_ratio, offset = offset, \\\n",
    "        progress_label = progress_label)    \n",
    "    \n",
    "    dataset_size = len(train_snapshot_list) + len(test_snapshot_list)\n",
    "    # generates the dataset by feeding in a tuple, of dictionaries (alternative would be a tuble of lists)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: train_past_snapshot_list},\n",
    "            {OUTPUT_NAME_1: train_snapshot_label_list, \n",
    "            OUTPUT_NAME_2: train_snapshot_list},\n",
    "            {OUTPUT_NAME_1: train_snapshot_weight_list,\n",
    "            OUTPUT_NAME_2: train_snapshot_weight_list})).shuffle(dataset_size)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: test_past_snapshot_list},\n",
    "            {OUTPUT_NAME_1: test_snapshot_label_list, \n",
    "            OUTPUT_NAME_2: test_snapshot_list},\n",
    "            {OUTPUT_NAME_1: test_snapshot_weight_list,\n",
    "            OUTPUT_NAME_2: test_snapshot_weight_list})).shuffle(dataset_size)\n",
    "\n",
    "    return train_ds, test_ds, \\\n",
    "            train_past_snapshot_list, train_snapshot_list, \\\n",
    "            train_snapshot_label_list, train_snapshot_weight_list, \\\n",
    "            test_past_snapshot_list, test_snapshot_list, \\\n",
    "            test_snapshot_label_list, test_snapshot_weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset):\n",
    "    for batch, label, weights in dataset.take(1):\n",
    "        for key, value in batch.items():\n",
    "            print(\"{:20s}: {}\".format(key,value.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
