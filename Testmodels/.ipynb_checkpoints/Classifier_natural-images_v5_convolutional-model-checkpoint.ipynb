{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "#import IPython.display as display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6899 images found.\n",
      "Existing classes: ['7' '5' '0' '2' '4' '3' '1' '6']\n"
     ]
    }
   ],
   "source": [
    "# a fancy way of setting AUTOTUNE to -1 so the maximum number of threads are run later\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "FOLDER_NAME = \"natural_images\"\n",
    "# set data_dir to be the path to the selected folder\n",
    "data_dir = pathlib.Path(str(FOLDER_NAME))\n",
    "# counts all JPG files in all subfolders of our selected folder\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(str(image_count) + \" images found.\")\n",
    "# makes a list of the subfolder names in our selected folder, which corresponds to the classes \n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "print(\"Existing classes: \" + str(CLASS_NAMES))\n",
    "#\n",
    "BATCH_SIZE = 1000\n",
    "# pick a size to which the images should be rescaled\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "# BUFFER_SIZE will be used for shuffling the dataset later on. \n",
    "# By selecting image_count as the size, the complete data set is guaranteed to be shuffled.\n",
    "BUFFER_SIZE = image_count\n",
    "# Sets a split size for train and test data set\n",
    "TRAIN_SIZE = int(image_count * 0.7)\n",
    "# choose whether the labels shoud be one hot encoded. This appears to be beneficial if labels aren't numeric.\n",
    "ONE_HOT = False\n",
    "# produces a time stamp to use for file naming\n",
    "TIME_STAMP = str(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffles the dataset an splits it into train and test test\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*')).shuffle(BUFFER_SIZE)\n",
    "train_list_ds = list_ds.take(TRAIN_SIZE)\n",
    "test_list_ds = list_ds.skip(TRAIN_SIZE)\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    if ONE_HOT == True:\n",
    "        # return the class (second to last element in the path) in one hot encoding\n",
    "        return parts[-2] == CLASS_NAMES\n",
    "    else:\n",
    "        # return the class (second to last element in the path) as an integer (if the folder is named as an integer)\n",
    "        return int(parts[-2])\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel by different cores. \n",
    "# -1 uses all cores.\n",
    "train_labeled_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_labeled_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=BUFFER_SIZE):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "    else:\n",
    "        # untested! If dataset is to large for memory, a time stamped cache file is produced to take data from\n",
    "        # if the code is run again with the same time stamp, the file will be reused. For new time stamps\n",
    "        # a new file will be generated.\n",
    "        ds = ds.cache(str(TIME_STAMP) + \"_cache.txt\")\n",
    "        \n",
    "    # shuffles the dataset again\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int32)>\n",
      "tf.Tensor(\n",
      "[[[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]\n",
      "\n",
      "\n",
      " [[[0.04509804 0.0372549  0.04901961]\n",
      "   [0.04411765 0.03627451 0.04803922]\n",
      "   [0.04411765 0.03627451 0.04019608]\n",
      "   ...\n",
      "   [0.1392157  0.10392158 0.02058824]\n",
      "   [0.09313726 0.07352941 0.02058824]\n",
      "   [0.05882353 0.04705883 0.00882353]]\n",
      "\n",
      "  [[0.04509804 0.0372549  0.04901961]\n",
      "   [0.04509804 0.0372549  0.04901961]\n",
      "   [0.04705883 0.03921569 0.04313726]\n",
      "   ...\n",
      "   [0.15490197 0.11666667 0.01764706]\n",
      "   [0.10000001 0.07254902 0.00294118]\n",
      "   [0.06078432 0.0382353  0.        ]]\n",
      "\n",
      "  [[0.04215686 0.03431373 0.04607844]\n",
      "   [0.04607844 0.0382353  0.05      ]\n",
      "   [0.04705883 0.03921569 0.04313726]\n",
      "   ...\n",
      "   [0.23235296 0.18137255 0.05882353]\n",
      "   [0.15588236 0.11764707 0.02058824]\n",
      "   [0.09803922 0.06176471 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.427451   0.37254906 0.3372549 ]\n",
      "   [0.43823534 0.39117652 0.34411764]\n",
      "   [0.44607848 0.39901966 0.35196078]\n",
      "   ...\n",
      "   [0.07745098 0.10882354 0.35686275]\n",
      "   [0.0882353  0.11862746 0.37647063]\n",
      "   [0.09901962 0.12843138 0.3892157 ]]\n",
      "\n",
      "  [[0.43921572 0.38823533 0.3529412 ]\n",
      "   [0.454902   0.4039216  0.3686275 ]\n",
      "   [0.4529412  0.41372553 0.36666667]\n",
      "   ...\n",
      "   [0.0627451  0.09509805 0.33529413]\n",
      "   [0.07156863 0.10294119 0.35000002]\n",
      "   [0.08431374 0.12352942 0.36666667]]\n",
      "\n",
      "  [[0.45392162 0.40294123 0.36764705]\n",
      "   [0.4696079  0.4186275  0.38333338]\n",
      "   [0.46764708 0.4284314  0.3892157 ]\n",
      "   ...\n",
      "   [0.04019608 0.0754902  0.30686277]\n",
      "   [0.05490196 0.08627451 0.32941177]\n",
      "   [0.07058824 0.10980393 0.34901962]]]\n",
      "\n",
      "\n",
      " [[[0.21317403 0.5896446  0.89160544]\n",
      "   [0.20816365 0.58463424 0.8865951 ]\n",
      "   [0.21728255 0.59136343 0.8941208 ]\n",
      "   ...\n",
      "   [0.22041664 0.6008088  0.9184559 ]\n",
      "   [0.2235153  0.60390747 0.92155457]\n",
      "   [0.22603187 0.60642403 0.92407113]]\n",
      "\n",
      "  [[0.21315752 0.5896281  0.8915889 ]\n",
      "   [0.21176472 0.5882353  0.89019614]\n",
      "   [0.21806666 0.5921475  0.8949049 ]\n",
      "   ...\n",
      "   [0.22343752 0.6038297  0.9214768 ]\n",
      "   [0.21991064 0.6003028  0.9179499 ]\n",
      "   [0.22348347 0.60387564 0.92152274]]\n",
      "\n",
      "  [[0.21176472 0.5882353  0.89019614]\n",
      "   [0.21176472 0.5882353  0.89019614]\n",
      "   [0.21727943 0.59136033 0.8941177 ]\n",
      "   ...\n",
      "   [0.2156097  0.59600186 0.91364896]\n",
      "   [0.21953724 0.5999294  0.9175765 ]\n",
      "   [0.21960786 0.6        0.9176471 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.24846815 0.6249387  0.922978  ]\n",
      "   [0.24314326 0.6196138  0.9176531 ]\n",
      "   [0.24399488 0.60870075 0.91458315]\n",
      "   ...\n",
      "   [0.24698225 0.62032783 0.9316637 ]\n",
      "   [0.25075063 0.62329966 0.9370252 ]\n",
      "   [0.24705884 0.61960787 0.9333334 ]]\n",
      "\n",
      "  [[0.24846815 0.6249387  0.922978  ]\n",
      "   [0.23956443 0.61603504 0.9140743 ]\n",
      "   [0.2431466  0.6078525  0.9137349 ]\n",
      "   ...\n",
      "   [0.25093445 0.62428004 0.9356159 ]\n",
      "   [0.25067404 0.62322307 0.9369486 ]\n",
      "   [0.24318323 0.61573225 0.9294578 ]]\n",
      "\n",
      "  [[0.24596572 0.62243634 0.92438185]\n",
      "   [0.24312314 0.61959374 0.92153925]\n",
      "   [0.24002448 0.60473037 0.91061276]\n",
      "   ...\n",
      "   [0.2556801  0.62823224 0.9419484 ]\n",
      "   [0.24737813 0.61992717 0.9336527 ]\n",
      "   [0.24954596 0.622095   0.9358205 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]\n",
      "\n",
      "\n",
      " [[[0.86372554 0.75       0.4911765 ]\n",
      "   [0.8843138  0.76666677 0.5235294 ]\n",
      "   [0.8803922  0.76666677 0.5392157 ]\n",
      "   ...\n",
      "   [0.2901961  0.3137255  0.14117648]\n",
      "   [0.29607844 0.31960785 0.13725491]\n",
      "   [0.3        0.32352942 0.13529412]]\n",
      "\n",
      "  [[0.837255   0.72352946 0.4647059 ]\n",
      "   [0.85       0.7401961  0.4911765 ]\n",
      "   [0.8617648  0.74803925 0.51862746]\n",
      "   ...\n",
      "   [0.28725493 0.31078434 0.13627452]\n",
      "   [0.29215688 0.3156863  0.13137256]\n",
      "   [0.29509807 0.32156864 0.12450981]]\n",
      "\n",
      "  [[0.81568635 0.7019608  0.43921572]\n",
      "   [0.8235295  0.7137255  0.46274513]\n",
      "   [0.84509814 0.7343137  0.5058824 ]\n",
      "   ...\n",
      "   [0.2784314  0.30784315 0.12941177]\n",
      "   [0.28725493 0.31862748 0.12843138]\n",
      "   [0.29215688 0.32352942 0.12352942]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15294118 0.15686275 0.13725491]\n",
      "   [0.15490197 0.15882353 0.1392157 ]\n",
      "   [0.15882353 0.1627451  0.14313726]\n",
      "   ...\n",
      "   [0.77450985 0.71274513 0.62254906]\n",
      "   [0.8235295  0.759804   0.672549  ]\n",
      "   [0.8568628  0.7931373  0.7058824 ]]\n",
      "\n",
      "  [[0.15294118 0.15686275 0.13725491]\n",
      "   [0.15490197 0.15882353 0.1392157 ]\n",
      "   [0.15882353 0.1627451  0.14313726]\n",
      "   ...\n",
      "   [0.79803926 0.7450981  0.67058825]\n",
      "   [0.85686284 0.7970589  0.72352946]\n",
      "   [0.8862746  0.8264706  0.75294125]]\n",
      "\n",
      "  [[0.15686275 0.16078432 0.14117648]\n",
      "   [0.15686275 0.16078432 0.14117648]\n",
      "   [0.15882353 0.1627451  0.14313726]\n",
      "   ...\n",
      "   [0.7725491  0.72156864 0.6578432 ]\n",
      "   [0.8617648  0.81078434 0.74705887]\n",
      "   [0.9196079  0.8568628  0.7970589 ]]]\n",
      "\n",
      "\n",
      " [[[0.23866303 0.28690895 0.06224593]\n",
      "   [0.46991712 0.5478244  0.25857803]\n",
      "   [0.10621098 0.11249869 0.01273205]\n",
      "   ...\n",
      "   [0.63546497 0.6496111  0.5149451 ]\n",
      "   [0.54865605 0.59209156 0.45823744]\n",
      "   [0.35832205 0.42061514 0.3043583 ]]\n",
      "\n",
      "  [[0.5888655  0.68780124 0.2931894 ]\n",
      "   [0.57640153 0.7047256  0.26244622]\n",
      "   [0.19663315 0.28667605 0.06511213]\n",
      "   ...\n",
      "   [0.38599068 0.42877087 0.3194418 ]\n",
      "   [0.19857869 0.27988994 0.16517203]\n",
      "   [0.17044565 0.28046733 0.17196949]]\n",
      "\n",
      "  [[0.598665   0.6785281  0.28136206]\n",
      "   [0.41880527 0.49247366 0.11481294]\n",
      "   [0.54142535 0.6242072  0.34251297]\n",
      "   ...\n",
      "   [0.21019188 0.28798684 0.1980795 ]\n",
      "   [0.1626967  0.28413805 0.18566991]\n",
      "   [0.20902035 0.35256767 0.25898972]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.41253772 0.45233554 0.43047583]\n",
      "   [0.4318569  0.45629126 0.44030333]\n",
      "   [0.41357467 0.44886878 0.42926094]\n",
      "   ...\n",
      "   [0.22106546 0.15439878 0.12302624]\n",
      "   [0.21525738 0.1485907  0.11721815]\n",
      "   [0.20283397 0.13616729 0.10479474]]\n",
      "\n",
      "  [[0.43498048 0.47666976 0.45830676]\n",
      "   [0.4512616  0.48717177 0.47984946]\n",
      "   [0.43724662 0.48231876 0.4666325 ]\n",
      "   ...\n",
      "   [0.22620545 0.15953878 0.12816624]\n",
      "   [0.19967288 0.1330062  0.10163366]\n",
      "   [0.19288087 0.12621419 0.09484164]]\n",
      "\n",
      "  [[0.4554841  0.49469978 0.4907782 ]\n",
      "   [0.4490769  0.48829257 0.484371  ]\n",
      "   [0.4452442  0.491292   0.48395437]\n",
      "   ...\n",
      "   [0.20833687 0.1416702  0.11029766]\n",
      "   [0.20661765 0.13995098 0.10857844]\n",
      "   [0.19440871 0.12774204 0.0963695 ]]]], shape=(1000, 128, 128, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_ds = prepare_for_training(train_labeled_ds)\n",
    "test_ds = prepare_for_training(test_labeled_ds)\n",
    "print(train_ds)\n",
    "# obtain the image and label batches for both test and training\n",
    "train_image_batch, train_label_batch = next(iter(train_ds))\n",
    "test_image_batch, test_label_batch = next(iter(test_ds))\n",
    "print(train_image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 1.8311 - sparse_categorical_accuracy: 0.3330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 0.7699 - sparse_categorical_accuracy: 0.7320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 0.4897 - sparse_categorical_accuracy: 0.8290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 0.2489 - sparse_categorical_accuracy: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 0.2144 - sparse_categorical_accuracy: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 0.1549 - sparse_categorical_accuracy: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 0.0600 - sparse_categorical_accuracy: 0.9860\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 0.0496 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 0.0228 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 0.0263 - sparse_categorical_accuracy: 0.9940\n",
      "\n",
      "1000/1000 - 3s - loss: 0.3641 - sparse_categorical_accuracy: 0.8910\n",
      "\n",
      "Test accuracy: 0.891\n"
     ]
    }
   ],
   "source": [
    "# build a sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    # use first layer to flatten the image and take all inputs\n",
    "    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    # add an arbitrary number of dense layers with an arbitrary number of nodes\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # add an output layer with as many nodes as existing lables\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(8, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#OPTIMIZER = \"RMSprop\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "#OPTIMIZER = \"SGD\"\n",
    "if ONE_HOT == True:\n",
    "    if OPTIMIZER == \"RMSprop\":\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    elif OPTIMIZER == \"Adam\":\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    elif OPTIMIZER == \"SGD\":\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.CategoricalAccuracy()])        \n",
    "else:\n",
    "    if OPTIMIZER == \"RMSprop\":\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.SpareCategoricalAccuracy()])\n",
    "    elif OPTIMIZER == \"Adam\":\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    elif OPTIMIZER == \"SGD\":\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.fit(train_image_batch, train_label_batch, epochs=10)\n",
    "print()\n",
    "test_loss, test_acc = model.evaluate(test_image_batch,  test_label_batch, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp22m62xwo\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp22m62xwo', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-21a6ae0d573e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m classifier.train(\n\u001b[1;32m     22\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     steps=5000)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m   1190\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[0;32m-> 1191\u001b[0;31m               input_fn, ModeKeys.TRAIN))\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       estimator_spec = self._call_model_fn(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[0;32m-> 1028\u001b[0;31m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_context'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-21a6ae0d573e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Train the Model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m classifier.train(\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     steps=5000)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-21a6ae0d573e>\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m(features, labels, training, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"An input function for training or evaluating\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Convert the inputs to a Dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Shuffle and repeat if you are in training mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iterating over `tf.Tensor`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    513\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    514\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
