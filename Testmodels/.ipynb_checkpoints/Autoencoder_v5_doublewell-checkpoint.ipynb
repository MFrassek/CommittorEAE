{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import pickle\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\"dim1\", \"dim2\", \"dim3\", \"dim4\", \n",
    "                \"dim5\", \"dim6\", \"dim7\", \"dim8\", \n",
    "                \"dim9\", \"dim10\", \"label\"]\n",
    "LABEL_NAME = \"label\"\n",
    "INPUT_NAMES = list(COLUMN_NAMES)\n",
    "INPUT_NAMES.remove(LABEL_NAME)\n",
    "full_snapshot_list = pickle.load(open(\"N-Dim_Doublewell/full_snapshot_list.p\", \"rb\"))\n",
    "full_label_list = pickle.load(open(\"N-Dim_Doublewell/full_label_list.p\", \"rb\"))\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "SHUFFLE_BUFFER_SIZE = 10000\n",
    "CORES_USED = 3\n",
    "# Sets a split size for train and test data set\n",
    "TRAIN_SIZE = int(len(full_label_list) * 0.7)\n",
    "\n",
    "snapshot_label_ds = tf.data.Dataset.from_tensor_slices((full_snapshot_list, full_label_list)).shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "snapshot_snapshot_ds = tf.data.Dataset.from_tensor_slices((full_snapshot_list, full_snapshot_list)).shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "train_ss_ds = snapshot_snapshot_ds.take(TRAIN_SIZE).batch(BATCH_SIZE)\n",
    "test_ss_ds = snapshot_snapshot_ds.skip(TRAIN_SIZE).batch(BATCH_SIZE)\n",
    "train_sl_ds = snapshot_label_ds.take(TRAIN_SIZE).batch(BATCH_SIZE)\n",
    "test_sl_ds = snapshot_label_ds.skip(TRAIN_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class PackNumericFeatures(object):\\n    def __init__(self, names):\\n        self.names = names\\n\\n    def __call__(self, features, labels):\\n\\n        numeric_features = [features.pop(name) for name in self.names]\\n        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\\n        numeric_features = tf.stack(numeric_features, axis=-1)\\n        print(numeric_features)\\n        #returns the features twice packed together which can be used as input and control output later on\\n        return numeric_features, numeric_features\\nclass Pack(object):\\n    def __init__(self, names):\\n        self.names = names\\n    def __call__(self, features, labels):\\n        pass'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class PackNumericFeatures(object):\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "\n",
    "    def __call__(self, features, labels):\n",
    "\n",
    "        numeric_features = [features.pop(name) for name in self.names]\n",
    "        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
    "        numeric_features = tf.stack(numeric_features, axis=-1)\n",
    "        print(numeric_features)\n",
    "        #returns the features twice packed together which can be used as input and control output later on\n",
    "        return numeric_features, numeric_features\n",
    "class Pack(object):\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "    def __call__(self, features, labels):\n",
    "        pass\"\"\"\n",
    "##packed_train_ds = train_ds.map(PackNumericFeatures(INPUT_NAMES))\n",
    "##packed_test_ds = test_ds.map(PackNumericFeatures(INPUT_NAMES))\n",
    "\n",
    "#numeric_column = tf.feature_column.numeric_column('numeric', shape=[len(INPUT_NAMES)])\n",
    "#numeric_columns = [numeric_column]\n",
    "#print(numeric_column)\n",
    "#print(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "took1 = train_ss_ds.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2, 10), dtype=float64, numpy=\n",
      "array([[-0.614,  0.225,  0.486,  0.159, -0.667,  0.409, -0.57 ,  0.639,\n",
      "         0.825, -0.654],\n",
      "       [-0.353,  0.174,  0.006,  0.872, -0.977, -0.767, -0.796,  0.062,\n",
      "         0.064, -0.529]])>, <tf.Tensor: shape=(2, 10), dtype=float64, numpy=\n",
      "array([[-0.614,  0.225,  0.486,  0.159, -0.667,  0.409, -0.57 ,  0.639,\n",
      "         0.825, -0.654],\n",
      "       [-0.353,  0.174,  0.006,  0.872, -0.977, -0.767, -0.796,  0.062,\n",
      "         0.064, -0.529]])>)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(took1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_snapshots = keras.Input(shape=(len(INPUT_NAMES),),name=\"snapshots\")\n",
    "x = keras.layers.Dense(len(INPUT_NAMES))(input_snapshots)\n",
    "x = keras.layers.Dense(len(INPUT_NAMES)*2, activation='tanh')(x)\n",
    "output_1 = keras.layers.Dense(2, activation='tanh')(x)\n",
    "output_2 = keras.layers.Dense(len(INPUT_NAMES), activation='tanh')(x)\n",
    "\n",
    "model = keras.Model(inputs=input_snapshots,outputs=[output_1,output_2])\n",
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 895 steps\n",
      "Epoch 1/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2280 - mean_squared_error: 0.2279\n",
      "Epoch 2/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2230 - mean_squared_error: 0.2230\n",
      "Epoch 3/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2201 - mean_squared_error: 0.2201\n",
      "Epoch 4/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2176 - mean_squared_error: 0.2177\n",
      "Epoch 5/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2168 - mean_squared_error: 0.2167\n",
      "Epoch 6/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2177 - mean_squared_error: 0.2177\n",
      "Epoch 7/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2186 - mean_squared_error: 0.2187\n",
      "Epoch 8/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2205 - mean_squared_error: 0.2205\n",
      "Epoch 9/10\n",
      "895/895 [==============================] - 2s 2ms/step - loss: 0.2181 - mean_squared_error: 0.2181\n",
      "Epoch 10/10\n",
      "895/895 [==============================] - 2s 3ms/step - loss: 0.2193 - mean_squared_error: 0.2193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb42a7b8850>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(len(INPUT_NAMES),input_shape=(len(INPUT_NAMES),)),\n",
    "    tf.keras.layers.Dense(len(INPUT_NAMES)*2, activation='tanh'),\n",
    "    tf.keras.layers.Dense(len(INPUT_NAMES)*2, activation='tanh'),\n",
    "    tf.keras.layers.Dense(2, activation='tanh'),\n",
    "    tf.keras.layers.Dense(len(INPUT_NAMES)*2, activation='tanh'),\n",
    "    tf.keras.layers.Dense(len(INPUT_NAMES)*2, activation='tanh'),\n",
    "    tf.keras.layers.Dense(len(INPUT_NAMES))])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                    loss=tf.keras.losses.MeanSquaredError(),\n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "tf.print\n",
    "\n",
    "model.fit(train_ss_ds, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 42        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,482\n",
      "Trainable params: 1,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.673 0.176], shape=(2,), dtype=float64)\n",
      "[-0.088  0.085]\n",
      "tf.Tensor(1.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "example_batch, label_batch = next(iter(train_sl_ds))    \n",
    "\n",
    "\n",
    "# with a Sequential model\n",
    "output = K.function([model.layers[0].input],\n",
    "                    [model.layers[3].output])\n",
    "layer_output = output(example_batch)[0]\n",
    "'''''''''''''''''''''''''''''''Do Stuff'\n",
    "#print(output)\n",
    "print(example_batch[0][:2])\n",
    "print(layer_output[0])\n",
    "print(label_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2169 - mean_squared_error: 0.2169\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ss_ds, verbose=1, steps = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name='autoencoder')\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
    "autoencoder.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
