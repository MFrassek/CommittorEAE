{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import time\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\"dim1\", \"dim2\", \"dim3\", \"dim4\", \n",
    "                \"dim5\", \"dim6\", \"dim7\", \"dim8\", \n",
    "                \"dim9\", \"dim10\", \"label\"]\n",
    "LABEL_NAME = \"label\"\n",
    "INPUT_NAMES = list(COLUMN_NAMES)\n",
    "INPUT_NAMES.remove(LABEL_NAME)\n",
    "trajectory_list = pickle.load(open(\"N-Dim_Doublewell/trajectory_list.p\", \"rb\"))\n",
    "trajectory_label_list = pickle.load(open(\"N-Dim_Doublewell/trajectory_label_list.p\", \"rb\"))\n",
    "BATCH_SIZE = 64\n",
    "#SHUFFLE_BUFFER_SIZE = 1000000\n",
    "CORES_USED = 3\n",
    "DIMENSIONS = 10\n",
    "# sets a random seed for reproducibility of the shuffling process\n",
    "SEED = 5\n",
    "OFFSET = 5\n",
    "DROP_REMAINDER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional section can be used for generation of present/future pairs\n",
    "def generate_offset_snapshot_list(trajectory_list, offset):\n",
    "    # Takes in a list or np.array of trajectories and an offset value and generates two np.arrays with respective new versions\n",
    "    # of the trajectories. \n",
    "    # present_trajectory_list contains all snapshots of the trajectories excluding\n",
    "    # the last n (speficified by offset) of each.\n",
    "    # future_trajectory_list contains all snapshots of the trajectories excluding\n",
    "    # the first n (specified by offset) of each.\n",
    "    # Consequently the both lists can be used as input and desired output of an autoencoder to\n",
    "    # train for future predictive variables.\n",
    "    present_trajectory_list = np.array([trajectory[:-offset] for trajectory in trajectory_list])  \n",
    "    #truncated_present_trajectory_list = \n",
    "    future_trajectory_list = np.array([trajectory[offset:] for trajectory in trajectory_list])\n",
    "    return present_trajectory_list, future_trajectory_list\n",
    "\n",
    "def get_snapshot_and_label_list(trajectory_list, trajectory_label_list, offset = 0, future = False, progress_label = False):\n",
    "    # takes in a list of trajectories and corresponding labels and generates concatenated lists of snapshots, \n",
    "    # snapshot label and snapshot progress labels\n",
    "    # can be used for present/future trajcetory lists by use or offset (same as used for generation of the list)\n",
    "    # and future = True for the future trajectory list\n",
    "    snapshot_list = []\n",
    "    snapshot_label_list = []\n",
    "    for trajectory_nr in range(len(trajectory_list)):\n",
    "        trajectory = trajectory_list[trajectory_nr]\n",
    "        trajectory_label = trajectory_label_list[trajectory_nr]\n",
    "        for snapshot_nr in range(len(trajectory)):\n",
    "            snapshot_list.append(trajectory[snapshot_nr])\n",
    "            if progress_label == False:\n",
    "                snapshot_label_list.append(trajectory_label)\n",
    "            else:\n",
    "                # Calculates the progress along the path for AB paths. If the path label is 1 or 0,\n",
    "                # all snapshot are assigned the same label. If the path label is different (e.g. 0.5),\n",
    "                # indicating a sucessfull transition a progress along the snapshots is calculated based on\n",
    "                # the position within the trajectory and the total trajectory length.\n",
    "                # For present/future lists, the offset needs to be taken into account in the denominator\n",
    "                # If the dataset is a future variant of an offset trajectory list the progress label \n",
    "                # needs to additionally take the offset into account in the nominator.\n",
    "                if trajectory_label == 0.0 or trajectory_label == 1.0:\n",
    "                    snapshot_label_list.append(trajectory_label)\n",
    "                else:\n",
    "                    if future == True:\n",
    "                        snapshot_label_list.append((snapshot_nr + offset)/(len(trajectory) - 1.0 + offset))\n",
    "                    else:\n",
    "                        snapshot_label_list.append(snapshot_nr/(len(trajectory)-1.0 + offset))\n",
    "    return np.array(snapshot_list), np.array(snapshot_label_list)\n",
    "\n",
    "def show_batch(dataset):\n",
    "    for batch, label in dataset.take(1):\n",
    "        for key, value in batch.items():\n",
    "            print(\"{:20s}: {}\".format(key,value.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snapshot_list, snapshot_label_list = get_snapshot_and_label_list(trajectory_list, trajectory_label_list)\n",
    "\n",
    "# Sets a split size for train and test data set\n",
    "#DATASET_SIZE = len(snapshot_label_list)\n",
    "#TRAIN_SIZE = int(DATASET_SIZE * 0.7)\n",
    "SPLIT_RATIO = 0.7\n",
    "BOTTLENECK_SIZE = 2\n",
    "LABEL_LOSS_WEIGHT = 1.0\n",
    "RECONSTRUCTION_LOSS_WEIGHT = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_train_test_split(trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False):\n",
    "    assert isinstance(split_ratio, float), \"Split ratio needs to be a of type float\"\n",
    "    if offset == 0 or offset == None:\n",
    "        snapshot_list, snapshot_label_list = get_snapshot_and_label_list(trajectory_list, \\\n",
    "                trajectory_label_list, progress_label = progress_label)\n",
    "        snapshot_list, snapshot_label_list = shuffle(snapshot_list, snapshot_label_list)\n",
    "        train_size = int(len(snapshot_label_list) * split_ratio)\n",
    "        train_snapshot_list = snapshot_list[:train_size].copy()\n",
    "        test_snapshot_list = snapshot_list[train_size:].copy()\n",
    "        train_snapshot_label_list = snapshot_label_list[:train_size].copy()\n",
    "        test_snapshot_label_list = snapshot_label_list[train_size:].copy()\n",
    "        \n",
    "        return train_snapshot_list, train_snapshot_label_list, test_snapshot_list, test_snapshot_label_list\n",
    "    else:\n",
    "        present_trajectory_list, future_trajectory_list = generate_offset_snapshot_list(trajectory_list, offset)\n",
    "        present_snapshot_list, _ = get_snapshot_and_label_list(\n",
    "                present_trajectory_list, trajectory_label_list, offset)\n",
    "        future_snapshot_list, future_snapshot_label_list = get_snapshot_and_label_list(\n",
    "                future_trajectory_list, trajectory_label_list, offset, future = True, \\\n",
    "                progress_label = progress_label)\n",
    "        present_snapshot_list, future_snapshot_list, future_snapshot_label_list = shuffle(\n",
    "                present_snapshot_list, future_snapshot_list, future_snapshot_label_list)\n",
    "        train_size = int(len(future_snapshot_label_list) * split_ratio)\n",
    "        \n",
    "        train_present_snapshot_list = present_snapshot_list[:train_size].copy()\n",
    "        test_present_snapshot_list = present_snapshot_list[train_size:].copy()\n",
    "        train_future_snapshot_list = future_snapshot_list[:train_size].copy()\n",
    "        test_future_snapshot_list = future_snapshot_list[train_size:].copy()\n",
    "        train_future_snapshot_label_list = future_snapshot_label_list[:train_size].copy()\n",
    "        test_future_snapshot_label_list = future_snapshot_label_list[train_size:].copy()   \n",
    "        return train_present_snapshot_list, train_future_snapshot_list, \\\n",
    "                train_future_snapshot_label_list, test_present_snapshot_list, \\\n",
    "                test_future_snapshot_list, test_future_snapshot_label_list\n",
    "\n",
    "def generate_ds(trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False):\n",
    "    if offset == 0 or offset == None:\n",
    "        train_snapshot_list, train_snapshot_label_list, \\\n",
    "                test_snapshot_list, test_snapshot_label_list = shuffled_train_test_split(\n",
    "                        trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False)\n",
    "        dataset_size = len(train_snapshot_list) + len(test_snapshot_list)\n",
    "        # generates the dataset by feeding in a tuple, of dictionaries (alternative would be a tuble of lists)\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices(({\"input_snapshots\": train_snapshot_list},\n",
    "                {\"label\": train_snapshot_label_list, \n",
    "                \"reconstruction\": train_snapshot_list})).shuffle(dataset_size)\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices(({\"input_snapshots\": test_snapshot_list},\n",
    "                {\"label\": test_snapshot_label_list, \n",
    "                \"reconstruction\": test_snapshot_list})).shuffle(dataset_size)\n",
    "        step_number = int(len(test_snapshot_list)/BATCH_SIZE)\n",
    "        \n",
    "        return dataset_size, step_number, train_ds, test_ds, train_snapshot_list, \\\n",
    "                [], train_snapshot_label_list, test_snapshot_list, \\\n",
    "                [], test_snapshot_label_list\n",
    "    else:\n",
    "        train_snapshot_list, train_future_snapshot_list, train_future_snapshot_label_list, \\\n",
    "                test_snapshot_list, test_future_snapshot_list, test_future_snapshot_label_list = shuffled_train_test_split(\n",
    "                        trajectory_list, trajectory_label_list, split_ratio, offset = offset, \\\n",
    "                        progress_label = False)\n",
    "        dataset_size = len(train_snapshot_list) + len(test_snapshot_list)\n",
    "        # generates the dataset by feeding in a tuple, of dictionaries (alternative would be a tuble of lists)\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices(({\"input_snapshots\": train_snapshot_list},\n",
    "                {\"label\": train_future_snapshot_label_list, \n",
    "                \"reconstruction\": train_future_snapshot_list})).shuffle(dataset_size)\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices(({\"input_snapshots\": test_snapshot_list},\n",
    "                {\"label\": test_future_snapshot_label_list, \n",
    "                \"reconstruction\": test_future_snapshot_list})).shuffle(dataset_size)\n",
    "        step_number = int(len(test_present_snapshot_list)/BATCH_SIZE)\n",
    "    \n",
    "        return dataset_size, step_number, train_ds, test_ds, train_snapshot_list, \\\n",
    "                train_future_snapshot_list, train_future_snapshot_label_list, test_snapshot_list, \\\n",
    "                test_future_snapshot_list, test_future_snapshot_label_list\n",
    "                \n",
    "\n",
    "DATASET_SIZE, STEP_NUMBER, train_ds, test_ds, train_snapshot_list, train_future_snapshot_list, \\\n",
    "        train_snapshot_label_list, test_snapshot_list, test_future_snapshot_list, \\\n",
    "        test_snapshot_label_list = generate_ds(trajectory_list, \\\n",
    "                trajectory_label_list, SPLIT_RATIO, offset = 0, progress_label = False)\n",
    "\n",
    "train_ds_batch = train_ds.batch(BATCH_SIZE, drop_remainder=DROP_REMAINDER)\n",
    "test_ds_batch = test_ds.batch(BATCH_SIZE, drop_remainder=DROP_REMAINDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(DIMENSIONS,),name=\"input_snapshots\")\n",
    "x = keras.layers.Dense(DIMENSIONS, activation= 'tanh')(encoder_input)\n",
    "x = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(x)\n",
    "x = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(x)\n",
    "encoder_output = keras.layers.Dense(BOTTLENECK_SIZE, activation='tanh', name='bottleneck')(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name =\"encoder\")\n",
    "#encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(BOTTLENECK_SIZE,), name =\"encoded_snapshots\")\n",
    "\n",
    "x1 = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(decoder_input)\n",
    "x1 = keras.layers.Dense(DIMENSIONS, activation='tanh')(x1)\n",
    "decoder_output_1 = keras.layers.Dense(1, activation='tanh',name=\"label\")(x1)\n",
    "decoder_1 = keras.Model(decoder_input, decoder_output_1, name=\"label\")\n",
    "#decoder_1.summary()\n",
    "\n",
    "x2 = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(decoder_input)\n",
    "x2 = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(x2)\n",
    "decoder_output_2 = keras.layers.Dense(DIMENSIONS, activation='tanh',name=\"reconstruction\")(x2)\n",
    "decoder_2 = keras.Model(decoder_input, decoder_output_2, name=\"reconstruction\")\n",
    "#decoder_2.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(DIMENSIONS,), name=\"input_snapshots\")\n",
    "encoded_snaphot = encoder(autoencoder_input)\n",
    "label_snapshot = decoder_1(encoded_snaphot)\n",
    "reconstructed_snapshot = decoder_2(encoded_snaphot)\n",
    "autoencoder = keras.Model(inputs=autoencoder_input, outputs=[label_snapshot,reconstructed_snapshot])\n",
    "\n",
    "model_layout = keras.utils.plot_model(autoencoder, 'multi_input_and_output_model.png', show_shapes=True)\n",
    "display.display(model_layout)\n",
    "#display.display(keras.utils.plot_model(encoder, 'encoder.png', show_shapes=True))\n",
    "#display.display(keras.utils.plot_model(decoder_1, 'decoder_1.png', show_shapes=True))\n",
    "#display.display(keras.utils.plot_model(decoder_2, 'decoder_2.png', show_shapes=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss={'label':keras.losses.MeanAbsoluteError(),\n",
    "                      'reconstruction': keras.losses.MeanAbsoluteError()},\n",
    "              loss_weights=[LABEL_LOSS_WEIGHT, RECONSTRUCTION_LOSS_WEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2521 steps\n",
      "Epoch 1/3\n",
      "2521/2521 [==============================] - 5s 2ms/step - loss: 0.4537 - label_loss: 0.0600 - reconstruction_loss: 0.3937\n",
      "Epoch 2/3\n",
      "2521/2521 [==============================] - 5s 2ms/step - loss: 0.4294 - label_loss: 0.0415 - reconstruction_loss: 0.3880\n",
      "Epoch 3/3\n",
      "2521/2521 [==============================] - 5s 2ms/step - loss: 0.4277 - label_loss: 0.0404 - reconstruction_loss: 0.3873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbc42f4c90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(train_ds_batch,epochs=3)\n",
    "#set back to 0 for proper tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 1ms/step - loss: 0.4270 - label_loss: 0.0403 - reconstruction_loss: 0.3868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42704669013619423, 0.04026953, 0.38677722]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(test_ds_batch, verbose=1, steps = STEP_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_generated_labels(model, x_list, y_list, dimensions, additional_dim_val, x_var_pos, y_var_pos):\n",
    "    assert x_var_pos != y_var_pos, \"x_var_pos and y_var_pos need to differ\"\n",
    "    label_map = []\n",
    "    for x in x_list:\n",
    "        label_current_row = []\n",
    "        for y in y_list:\n",
    "            label_current_row.append(model.predict([[x if x_var_pos == pos_nr else y if \\\n",
    "                    y_var_pos == pos_nr else additional_dim_val for pos_nr in range(dimensions)]])[0][0][0])\n",
    "        label_map.append(label_current_row)\n",
    "    return np.array(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_given_labels_efficiently(snapshot_list, snapshot_label_list, x_list, y_list, x_var_pos, y_var_pos):\n",
    "    x_nr = len(x_list)\n",
    "    y_nr = len(y_list)\n",
    "    min_x = min(x_list)\n",
    "    max_x = max(x_list)\n",
    "    min_y = min(y_list)\n",
    "    max_y = max(y_list)\n",
    "    # generate a list of lists of lists to store all labels in\n",
    "    label_map = [[[] for y in y_list] for x in x_list]\n",
    "    # sort the labels of each snapshot to the corresponding \"positions\" in the grid (by sorting them in the list)\n",
    "    for snapshot_nr in range(len(snapshot_list)):\n",
    "        x_snap = snapshot_list[snapshot_nr][x_var_pos]\n",
    "        y_snap = snapshot_list[snapshot_nr][y_var_pos]\n",
    "        # int to be able to use for iteration, round to round to closest full number, \n",
    "        # i-min_x to offset to start at 0, /2.0*(x-nr-1) to rescale\n",
    "        x_int = int(round((x_snap - min_x)/2.0*(x_nr-1)))\n",
    "        y_int = int(round((y_snap - min_y)/2.0*(y_nr-1)))\n",
    "        label_map[x_int][y_int].append(snapshot_label_list[snapshot_nr])\n",
    "\n",
    "    for row_ind in range(len(label_map)):\n",
    "        for col_ind in range(len(label_map[row_ind])):\n",
    "            if len(label_map[row_ind][col_ind]) > 0:\n",
    "                label_map[row_ind][col_ind] = np.mean(label_map[row_ind][col_ind])\n",
    "            else:\n",
    "                label_map[row_ind][col_ind] = float('NaN')\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(label_map, title, x_name, y_name, vmin, vmax):\n",
    "    plt.close()\n",
    "    # use transpose to rotate the map into the right orientation\n",
    "    # use [::-1] to invert the new y_axis\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(np.transpose(label_map)[::-1], cmap='coolwarm', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    #plt.axis('off')\n",
    "    plt.tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False, # labels along the bottom edge are off\n",
    "        left = False,\n",
    "        labelleft= False)     \n",
    "    plt.xlabel(\"{}\".format(x_name))\n",
    "    plt.ylabel(\"{}\".format(y_name))\n",
    "    plt.savefig(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD1CAYAAACIsbNlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAJtElEQVR4nO3dXWyWZx3H8d9FXyhvHe/uRWjHhrAd+LbiTIBgsiw4A9kSTYxGR9RDNfFIozHTTBMTT5d45pHG9+gcLEvEmLE5tqRlmvmCZRsbsHUdhQKltGufPr08aA8IAv7b57779Pk930+yZCn/XPdN2XdX212775RzFgAfS+p9AwCKRdSAGaIGzBA1YIaoATOtZSy6fv363N3dXcbSAGYdO3bsXM55w7UfLyXq7u5u9fX1lbE0gFkppVPX+zhffgNmiBowQ9SAGaIGzBA1YIaoATNEDZghasBMKYdPgMXoUOu2wtfcN9Vf+Jq1YqcGzBA1YIaoATNEDZghasAMUQNmiBowQ9SAGaIGzBA1YIZjoovcyddfC81tuevuku/k5so4gon5YacGzBA1YIaoATNEDZghasAMUQNmiBowQ9SAGaIGzHCiLGDn/iOFr7n/0V2huX0fWRGaGzz+cvjaA1/7emhuZGA0vGbUxo+vCc2dfelC4dcuQ/Qk3UI+oJCdGjBD1IAZogbMEDVghqgBM0QNmCFqwAxRA2aIGjBD1ICZhjkmWsZRzaK1dywNz54bei80d+byutDc+l9+M3ztD3w6dkQ1T+fwmm8f+Vto7vK7saOn939nZ/jabz57PDQ3fj72OR/pHwtfezFipwbMEDVghqgBM0QNmCFqwAxRA2aIGjBD1IAZogbMNMyJsnrafO+W0Nx0dTq8Zu+f/x6aOzsYu/Z9B2IPE5Sk1jdiDynMly+G12xbHjtNN3J6MDR3/viZ8LWjVt66PDS3YXvsFJ8kvf7H4u+zVuzUgBmiBswQNWCGqAEzRA2YIWrADFEDZogaMEPUgJmmPlG2pKUlNHfxbOy1qi2tsfUkaUPXbaG59vbYH9HBwR3ha39+/PnYYIr/O7+za2NormPNO6G5of7z4WtXK9XwbDNgpwbMEDVghqgBM0QNmCFqwAxRA2aIGjBD1IAZogbMEDVgxu6YaEopPJunYw8KHDkXOybatrQ9fO3x0djrUlvbYn9EY7G3tEqSzn9ob2hu7Yu/D6958vA/Q3NXBmI3OjUSP/qZ2mJ/5rkSezXv6Ktz+GQuQuzUgBmiBswQNWCGqAEzRA2YIWrADFEDZogaMEPUgJmGOVG2at3q0Nz4yGh4zepUsQ+sK3o9SRofHQ/NDV+cCq95eqorNLdq6Fx4zepk7HRe9FTXXFTH4q8QrpdDrdvCs/um+mu6Fjs1YIaoATNEDZghasAMUQNmiBowQ9SAGaIGzBA1YKauJ8p27j8Snm3vWBqam6rET1ZFvXBwT2hu9yN/Da8ZfT5aZaISXjNqSzoRmpuew+cytcSfDRfRsiy+33xq/N+hubmc6mpk7NSAGaIGzBA1YIaoATNEDZghasAMUQNmiBowQ9SAGaIGzDTMgwcrE5OFrxk9/hn1/JO7wrOf+MyLobnoq2wnJ+IP3xtqvSM0t2ZgKLxm5Uqxx3P3DseOfs5F9IF+ZRwnrfVhgnPBTg2YmVfUKaUHi74RAMWY707900LvAkBhbvgNW0rpqRv9kqR15dwOgFrd7KcwuyV9QdK1r7xIkj5W2h0BqMnNon5J0ljO+X+eZJBSWrgf5QGYkxtGnXN+SJJSSvfmnK/97wuPlXpXAOYt8oOy36SUvpVmLEspPSHpR2XfGID5iUR9v6RNko5K6pU0IGlnmTcFYP4ix5UqksYlLZPUIemNnPOCvzs05+JfgRp98GEZDx5saW0JzUV/3++8PRK+dnuKnc7L0/HPedEPHnym857w7EMjx0Nz9Xzw4GJ7lW2vZqLeIWmXpM+llH5X01UBlCayU38l59w3+/eDkh5OKX2xxHsCUIP/u1NfFfTVH/tZObcDoFb8Dx2AGaIGzBA1YIaoATNEDZghasAMUQNmGubBg/UUPU6aUvyoZJ6OzY4OXwrN3bKuM3zt8ellobnO5bF3gktS+4rYP0oTwfdOV4fjDzKs5/HPluXB38/Ywp2sZqcGzBA1YIaoATNEDZghasAMUQNmiBowQ9SAGaIGzNT1RNlcXiUbPdVVhujrZKtT1fiaS9tDcxs2vS82d/st4WtvHfpTaK56+8bwml27Y/vDfw6+EpqbnMOJsqJPdbV1xh4KKUldD8ReC7z9t4fDa9aKnRowQ9SAGaIGzBA1YIaoATNEDZghasAMUQNmiBow09TPKIueFFt96/rQ3KWzw+Frt3fEnv+1fFXseWJb714RvvYTAw+H5r60d1N4zZXPxl6EOvZmb3jNqJboc8+CJ8qq4/Hnib32h9Ohue3hFWvHTg2YIWrADFEDZogaMEPUgBmiBswQNWCGqAEzRA2YIWrATFMfE40+KHBk6EJorjIxGb529Jjo5u7VobkPbh4NX/vpo22huRP5nvCaPZ2xV+lu2Rc7elqtxI9qjr57OTQ3dD72WuDpSg5fe99Uf3h2obBTA2aIGjBD1IAZogbMEDVghqgBM0QNmCFqwAxRA2aa+kRZzrGTQ5PvTRR+7SuXYqeg+p47EZp761T8tbMn/3E8NPfdJU+H1zyz58uhuc2b7grN/eWB74Wvve2zW0JzQ72xE2WL8ZTYXLBTA2aIGjBD1IAZogbMEDVghqgBM0QNmCFqwAxRA2Ya5kTZCwf3FL7mzv1HCl8zKvr7id7jhcFztdzOdT259fvh2Z9847nQ3LefiZ8Ui+r/9cnQXKOfFItipwbMEDVghqgBM0QNmCFqwAxRA2aIGjBD1IAZogbMEDVgJkUfvjcXPT09ua+vr/B1sbAOtW6r27Wb5UhnLVJKx3LOPdd+nJ0aMEPUgBmiBswQNWCGqAEzRA2YIWrADFEDZogaMNMwDx7EwuNUV2NipwbMEDVghqgBM0QNmCFqwAxRA2aIGjBD1IAZogbMEDVghqgBM0QNmCFqwAxRA2aIGjBD1IAZogbMEDVghqgBM0QNmCnlVbYppSFJpwpfGMDVunLOG679YClRA6gfvvwGzBA1YIaoATNEDUlSSulASunV2b8O1Pt+MH/8oAxKKa2V1CepR1KWdEzSfTnnC3W9McwLO3WTSSntSCm9klLqSCmtSCn9S9JXJR3OOQ/PhnxY0ifre6eYL16Q12Ryzr0ppack/VDSMkk/l1SRdOaqsbck3VGH20MB2Kmb0+OSHtTMl9s/lpSuM8P3ZQ2KqJvTWkkrJa2S1KGZnXnTVb/+fkkDdbgvFIAflDWh2S+/fyXpTkm3SXpMMz8c++jsyMua+UHZcH3uELXge+omk1J6VNJUzvkXKaUWSUclfVjSDyT1zo49TtCNi50aMMP31IAZogbMEDVghqgBM0QNmCFqwAxRA2b+C5i46l15qdvcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RESOLUTION = 21\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if j > i:\n",
    "            print(i, j)\n",
    "            label_map_generated = map_generated_labels(autoencoder, \\\n",
    "                    np.linspace(-1,1,RESOLUTION), np.linspace(-1,1, RESOLUTION), DIMENSIONS, 0, i, j)\n",
    "            plot_heatmap(label_map_generated, \"{}{}_21_label_map_generated.png\".format(i,j), \\\n",
    "                    \"x{}\".format(i), \"x{}\".format(j), 0, 1)\n",
    "            label_map_given = map_given_labels_efficiently(train_snapshot_list, \\\n",
    "                    train_snapshot_label_list, np.linspace(-1,1,RESOLUTION), np.linspace(-1,1,RESOLUTION), i, j)\n",
    "            plot_heatmap(label_map_given, \"{}{}_21_label_map_given.png\".format(i,j), \\\n",
    "                    \"x{}\".format(i), \"x{}\".format(j), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_generated_bottleneck(model, x_list, y_list, dimensions, additional_dim_val, x_var_pos, y_var_pos, bottlenek_node_nr):\n",
    "    assert x_var_pos != y_var_pos, \"x_var_pos and y_var_pos need to differ\"\n",
    "    output_map = [[] for i in range(bottlenek_node_nr)]\n",
    "    for x in x_list:\n",
    "        output_current_row = [[] for i in range(bottlenek_node_nr)]\n",
    "        for y in y_list:\n",
    "            prediction = model.predict([[x if x_var_pos == pos_nr else y if \\\n",
    "                    y_var_pos == pos_nr else additional_dim_val for pos_nr in range(dimensions)]])[0]\n",
    "            for subrow_nr in range(bottlenek_node_nr):\n",
    "                output_current_row[subrow_nr].append(prediction[subrow_nr])      \n",
    "        for subarray_nr in range(bottlenek_node_nr):\n",
    "            output_map[subarray_nr].append(output_current_row[subarray_nr])\n",
    "    return np.array(output_map)\n",
    "\n",
    "bottleneck_map_generated = map_generated_bottleneck(encoder, \\\n",
    "        np.linspace(-1,1,RESOLUTION), np.linspace(-1,1, RESOLUTION), DIMENSIONS, 0, 0, 1, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(bottleneck_map_generated[0], \"{}{}_21_bottleneck_map_generated_b0.png\".format(0,1), \"x0\", \"x1\", -1, 1)\n",
    "plot_heatmap(bottleneck_map_generated[1], \"{}{}_21_bottleneck_map_generated_b1.png\".format(0,1), \"x0\", \"x1\", -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_generated_label_from_bn(model, x_list, y_list, dimensions, additional_dim_val, x_var_pos, y_var_pos):\n",
    "    assert x_var_pos != y_var_pos, \"x_var_pos and y_var_pos need to differ\"\n",
    "    label_map = []\n",
    "    for x in x_list:\n",
    "        label_current_row = []\n",
    "        for y in y_list:\n",
    "            label_current_row.append(model.predict([[x if x_var_pos == pos_nr else y \\\n",
    "                    if y_var_pos == pos_nr else additional_dim_val for pos_nr in range(dimensions)]])[0][0])\n",
    "        label_map.append(label_current_row)\n",
    "    return np.array(label_map)\n",
    " \n",
    "label_map_from_bn = map_generated_label_from_bn(decoder_1, np.linspace(-1,1,RESOLUTION), \\\n",
    "        np.linspace(-1,1, RESOLUTION), BOTTLENECK_SIZE, 0, 0, 1)\n",
    "plot_heatmap(label_map_from_bn, \"{}{}_21_label_map_from_bn.png\".format(0,1), \"b0\", \"b1\", 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misusing map generated_bottleneck here, since it has the same functionality of generating an array of maps for each output\n",
    "reconstructed_map_from_bn = map_generated_bottleneck(decoder_2, np.linspace(-1,1,RESOLUTION), \\\n",
    "        np.linspace(-1,1, RESOLUTION), BOTTLENECK_SIZE, 0, 0, 1, 10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD1CAYAAACIsbNlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAGYUlEQVR4nO3dv4tsZx3H8e9Xogg2uhARVpJYyG1ES39go3ZiYSFCwB+Flf4n2iiICOkiFgoBTWMbkAS0ChpNExBuIjYRFK0UyWOREa439949u3OeOXs+83pVOzPL7LOz973PzM73ntNjjAJyvGvrBQDrEjWEETWEETWEETWEeWzGnV5cXIzLy8sZd32rdXknYRNn+g7OK3989a9jjMfvv35K1JeXl/X8L38x466v1Bv+gGdE3eOt1e9z8dfeyS+pLR+jLT1x52N3H3S9p98QRtQQRtQQRtQQRtQQRtQQRtQQRtQQZsrwCesZvez37owBjFG9+HO3HFRZ+hgttfdhFjs1hBE1hBE1hBE1hBE1hBE1hBE1hBE1hBE1hBE1hNnNmOiWxx7bg+uMSm49UrpE0tjpqe179cA7iBrCiBrCiBrCiBrCiBrCiBrCiBrCiBrCTJsoMwHGMdaeUKvaz1k8j2WnhjCihjCihjCihjCihjCihjCihjCihjCihjCihjC7OfDgltLGC7c85/WWZoye3kZ2aggjaggjaggjaggjaggjaggjaggjaggjaghz1hNlaZNia5txSte0KbXbyE4NYUQNYUQNYUQNYUQNYUQNYUQNYUQNYUQNYXYzUWb6K8OMKbW1zZh6O+X3ffsfYeBaRA1hRA1hRA1hRA1hRA1hRA1hRA1hRA1hRA1hpoyJdg1jnezWHkZZH2XfqwfeQdQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQRtQQZsqpbNOM6tXv06l+mcVODWFuHHV3P7PmQoB1PPLpd3dfPOymqvri+ssBjnXVa+o3q+pu1f+9qByHyx+ctSjg5q6K+k9V9YUxxuv339Ddb8xZEnCMq15T/6CqPvCQ27638lqAFTxypx5j/KiqqrvfW1XfqarP1ttPv1+sqh9PXx1wbUvfp/5JVf2zqn54uPz04bqvzlgUcHNLo74zxvjEPZdf6O7fzVgQcJylUb/c3Z8aY/ymqqq7P1lVLx37xWdMau3Flt+7abZsV71P/Uq9/Rr63VX1je5+/XD5yap6df7ygOu6aqf+0klWAazmqr9+3z3VQoB1+A8dEEbUEEbUEEbUEEbUEEbUEEbUEGbKgQdH9VmPgN52S382xkn3yU4NYUQNYUQNYUQNYUQNYUQNYUQNYUQNYUQNYZzKloe6zlSg6bNH6/HWyb6WnRrCiBrCiBrCiBrCiBrCiBrCiBrCiBrCiBrCbDpRNnofxzHrYVrqnJxy+msGOzWEETWEETWEETWEETWEETWEETWEETWEETWEETWEmTYmupcR0CVmfC9GT09v7+OfS9mpIYyoIYyoIYyoIYyoIYyoIYyoIYyoIYyoIYxT2W5k7Sm1c55Q28Ok2ClP9WunhjCihjCihjCihjCihjCihjCihjCihjCihjDzjlF2hr8vum7/ZBPrOuWk2FLnVx6EEzWEETWEETWEETWEETWEETWEETWEETWEETWEmTgmus2pbLcc27vOaOzaI6XXOZDhOR+kcImtRz+PPZCinRrCiBrCiBrCiBrCiBrCiBrCiBrCiBrCiBrCxJ3KdsYk24wJo6XTZ3s5mOHSx33raa2tnPJ0u3ZqCCNqCCNqCCNqCCNqCCNqCCNqCCNqCCNqCCNqCDNpTLSjDjy45QjkjHHSpQcpdIDCbRz778hODWFEDWFEDWFEDWFEDWFEDWFEDWFEDWFEDWF6TJga6u43q+ru6ncM3OvJMcbj9185JWpgO55+QxhRQxhRQxhRn6Hufqq7//CA6z/S3b/t7te6++fd/Z4t1sdxRM29vltV3x9jfLSq/lZV39p4PdyAqM/XY939bHf/vruf6+73VdXnq+q5w+3PVtWXt1seNyXq83Wnqp4ZY3y8qv5RVd+uqr+PMf5zuP3PVXW51eK4OVGfrzfGGC8dPv5pVX3uAZ9jiGGHRH2+7g/231X1/u7+33HrPlxVfzntkliDqM/XE9396cPHT1fVi1X1QlV95XDdN6vq+S0WxnGMiZ6h7n6qqn5VVb+uqs9U1WtV9fWq+lBV/ayqLqrq5ar62hjjX9uskpsSNYTx9BvCiBrCiBrCiBrCiBrCiBrCiBrC/Bc54+Y1CQQQowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(reconstructed_map_from_bn[0], \"{}{}_21_label_map_from_bn_0.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[1], \"{}{}_21_label_map_from_bn_1.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[2], \"{}{}_21_label_map_from_bn_2.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[3], \"{}{}_21_label_map_from_bn_3.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[4], \"{}{}_21_label_map_from_bn_4.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[5], \"{}{}_21_label_map_from_bn_5.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[6], \"{}{}_21_label_map_from_bn_6.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[7], \"{}{}_21_label_map_from_bn_7.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[8], \"{}{}_21_label_map_from_bn_8.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[9], \"{}{}_21_label_map_from_bn_9.png\".format(0,1), \"b0\", \"b1\", -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbColumn(object):\n",
    "    def __init__(self, mod_along, perturbation, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.perturbation = perturbation\n",
    "        self.dimensions = dimensions\n",
    "        \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        perturbation = self.perturbation\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains random values between 1 - perturbation and 1 + perturbation\n",
    "        # multiplies the input with that matrix to perturb exactly that column of the input uniformly\n",
    "        for key in features.keys():\n",
    "            rand_array = np.random.uniform(1 - perturbation, 1 + perturbation,(BATCH_SIZE, 1))\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            mult_array[:,mod_along] = mult_array[:,mod_along]*rand_array[:,0]\n",
    "            features[key] = features[key] * mult_array\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_mean_of_batched_ds(dataset, key):\n",
    "    # takes all batches and concatenates them back together to get a big list of snapshots\n",
    "    # np.mean is then used to calculate the mean of each column\n",
    "    return np.mean(np.concatenate(np.array([batch[key].numpy() for batch, label in dataset])),axis = 0)\n",
    "\n",
    "class SetMeanColumn(object):\n",
    "    def __init__(self, mod_along, column_mean, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.column_mean = column_mean\n",
    "        self.dimensions = dimensions\n",
    "        \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        column_mean = self.column_mean\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains only zeros\n",
    "        # generates an add_array with only value \"0\" in all columns except for the modified column\n",
    "        # which contains the mean value of the column\n",
    "        # multiplies the input with the mult_array to set the values of the modified column to zero\n",
    "        # adds to the input the add_array to set the values of the modified column to the mean \n",
    "        for key in features.keys():\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            add_array = np.zeros((BATCH_SIZE, dimensions))\n",
    "            mult_array[:,mod_along] = 0.0\n",
    "            add_array[:,mod_along] = column_mean\n",
    "            features[key] = features[key] * mult_array\n",
    "            features[key] = features[key] + add_array\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HIPRColumn(object):\n",
    "    def __init__(self, mod_along, min_value, max_value, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.dimensions = dimensions\n",
    "    \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        min_value = self.min_value\n",
    "        max_value = self.max_value\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains only zeros\n",
    "        # generates an add_array with only value \"0\" in all columns except for the modified column\n",
    "        # which contains random values between min_value and max_value\n",
    "        # multiplies the input with the mult_array to set the values of the modified column to zero\n",
    "        # adds to the input the add_array to set the values of the modified column to random values \n",
    "        for key in features.keys():\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            add_array = np.zeros((BATCH_SIZE, dimensions))\n",
    "            rand_array = np.random.uniform(min_value, max_value,(BATCH_SIZE, 1))\n",
    "            mult_array[:,mod_along] = 0.0\n",
    "            add_array[:,mod_along] = rand_array[:,0]            \n",
    "            features[key] = features[key] * mult_array\n",
    "            features[key] = features[key] + add_array\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy \n",
    "def get_columns_from_batched_ds(dataset, key):\n",
    "    # reconstructs the snapshot list based on the batched dataset that is given\n",
    "    # transposes the dataset to have easy access to the columns\n",
    "    # shuffles each column separately\n",
    "    # returns the array back to its orriginal shape with all columns appearing in new permutations\n",
    "    reconstructed_list = np.concatenate(np.array([batch[key].numpy() for batch, label in dataset]))\n",
    "    reconstructed_list = np.transpose(reconstructed_list)\n",
    "    return reconstructed_list\n",
    "\n",
    "class ShuffleColumn(object):\n",
    "    def __init__(self, mod_along, shuffled_column, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.shuffled_column = shuffled_column\n",
    "        self.dimensions = dimensions\n",
    "    \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        shuffled_column = shuffle(self.shuffled_column)\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains only zeros\n",
    "        # generates an add_array with only value \"0\" in all columns except for the modified column\n",
    "        # which contains shuffled values from the column\n",
    "        # multiplies the input with the mult_array to set the values of the modified column to zero\n",
    "        # adds to the input the add_array to set the values of the modified column to other values from the column \n",
    "        for key in features.keys():\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            add_array = np.zeros((BATCH_SIZE, dimensions))\n",
    "# the generation of the shuffle array seems quite inefficient so far\n",
    "# maybe pick random slices from the column or find way to pop miltiple items at once\n",
    "            shuffle_array = np.transpose([shuffle(shuffled_column)[:BATCH_SIZE]])\n",
    "# unsure whether this actually works\n",
    "#            shuffle_array = np.transpose([shuffled_column[:BATCH_SIZE]])\n",
    "#            shuffled_column = shuffled_column[BATCH_SIZE:]\n",
    "#            shuffled_column = deepcopy(shuffled_column[BATCH_SIZE:])\n",
    "            print(shuffled_column[0])\n",
    "            mult_array[:,mod_along] = 0.0\n",
    "            add_array[:,mod_along] = shuffle_array[:,0]            \n",
    "            features[key] = features[key] * mult_array\n",
    "            features[key] = features[key] + add_array\n",
    "        return features, labels\n",
    "            \n",
    "\n",
    "#print(test_snapshot_list.shape)          \n",
    "#get_shuffled_snapshot_list_from_batched_ds(test_ds, \"input_snapshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: perturb\n",
      "Repetition 1.\n",
      "\tPerturbing variable 0.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /home/martin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /home/martin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /home/martin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected input_snapshots to have 2 dimensions, but got array with shape (64, 64, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-742d948cc683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mperturbed_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"perturb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIMENSIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;31m#plot_input_importance(perturbed_loss_list,1,\"Input_perturbation\",\"0.5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mmean_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_column_mean_of_batched_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_snapshots\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIMENSIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-742d948cc683>\u001b[0m in \u001b[0;36minput_importance\u001b[0;34m(mode, mode_var, model, test_ds, dimensions, check_vars, repetitions)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m69\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# calculate the different losses with the new dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mt_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_test_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEP_NUMBER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;31m# append the losses to a collective list for later comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_loss\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0morig_t_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /home/martin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /home/martin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /home/martin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected input_snapshots to have 2 dimensions, but got array with shape (64, 64, 10)\n"
     ]
    }
   ],
   "source": [
    "def input_importance(mode, mode_var, model, test_ds, dimensions, check_vars, repetitions):\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds_batch, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    # initialization dependent on the mode\n",
    "    if mode == \"perturb\":\n",
    "        perturbation = mode_var\n",
    "    elif mode == \"mean\":\n",
    "        if repetitions > 1:\n",
    "            \"Evaluation occurs on the basis of all batches of size BATCH_SIZE, thereby yielding a reliably result even at only one repetition.\"\n",
    "        mean_value_array = mode_var\n",
    "#        test_ds_list = []\n",
    "    elif mode == \"HIPR\":\n",
    "        min_value = mode_var[0]\n",
    "        max_value = mode_var[1]\n",
    "    elif mode == \"shuffle\":\n",
    "        column_array = mode_var\n",
    "        \n",
    "    print(\"Mode: {}\".format(mode))\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            # mapping of the dataset depending on the code\n",
    "            if mode == \"perturb\":\n",
    "                mod_test_ds = test_ds.map(PerturbColumn(variable_nr, perturbation, dimensions), CORES_USED).batch(BATCH_SIZE, drop_remainder=True)\n",
    "            elif mode == \"mean\":\n",
    "                mod_test_ds = test_ds.map(SetMeanColumn(variable_nr, mean_value_array[variable_nr], dimensions), CORES_USED).batch(BATCH_SIZE, drop_remainder=True)\n",
    "#                    test_ds_list.append(mod_test_ds)\n",
    "            elif mode == \"HIPR\":\n",
    "                mod_test_ds = test_ds.map(HIPRColumn(variable_nr, min_value, max_value, dimensions), CORES_USED).batch(BATCH_SIZE, drop_remainder=True)\n",
    "                new_columns = get_columns_from_batched_ds(mod_test_ds, \"input_snapshots\")\n",
    "                print(new_columns[variable_nr][:5]) #testing\n",
    "                print(new_columns[variable_nr][64:69]) #testing\n",
    "            elif mode == \"shuffle\":\n",
    "                mod_test_ds = test_ds.map(ShuffleColumn(variable_nr, column_array[variable_nr], dimensions), CORES_USED).batch(BATCH_SIZE, drop_remainder=True)\n",
    "                new_columns = get_columns_from_batched_ds(mod_test_ds, \"input_snapshots\")\n",
    "                print(new_columns[variable_nr][:5]) #testing\n",
    "                print(new_columns[variable_nr][64:69]) #testing\n",
    "            # calculate the different losses with the new dataset\n",
    "            t_loss, l_loss, r_loss = model.evaluate(mod_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,r_loss-orig_r_loss))\n",
    "        # average over the loss lists\n",
    "        # negative increases of loss are set to zero\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))                \n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "\n",
    "def plot_input_importance(loss_list, loss_type, name, perturbation):\n",
    "    variable_nr = len(loss_list[0])\n",
    "    plt.bar(range(variable_nr),loss_list[loss_type])\n",
    "    if perturbation == None:\n",
    "        plt.savefig(\"{}_{}.png\".format(name,loss_type))        \n",
    "    else:\n",
    "        plt.savefig(\"{}_{}_pert_{}.png\".format(name,loss_type,perturbation))\n",
    "    plt.close()\n",
    "    \n",
    "perturbed_loss_list = input_importance(\"perturb\", 0.5, autoencoder, test_ds, DIMENSIONS, range(3), 1)\n",
    "#plot_input_importance(perturbed_loss_list,1,\"Input_perturbation\",\"0.5\")\n",
    "mean_loss_list = input_importance(\"mean\", get_column_mean_of_batched_ds(test_ds, \"input_snapshots\"), autoencoder, test_ds, DIMENSIONS, range(3), 1)\n",
    "#plot_input_importance(mean_loss_list,1,\"Stepwise\", None)\n",
    "hipr_loss_list = input_importance(\"HIPR\", [-0.9,0.9], autoencoder, test_ds, DIMENSIONS, range(3), 3)\n",
    "#plot_input_importance(hipr_loss_list,1,\"HIPR\", None)\n",
    "shuffle_loss_list = input_importance(\"shuffle\", get_columns_from_batched_ds(test_ds, \"input_snapshots\"), autoencoder, test_ds, DIMENSIONS, range(1), 1)\n",
    "#plot_input_importance(shuffle_loss_list,1,\"Shuffle\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder.predict(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ({encoded_snapshots: (None, 2)}, {label: (None,)}), types: ({encoded_snapshots: tf.float32}, {label: tf.float64})>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49960995233721206"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bn_ds = tf.data.Dataset.from_tensor_slices(({\"encoded_snapshots\": encoder.predict(test_ds)},\n",
    "                                            {\"label\": test_snapshot_label_list})).shuffle(DATASET_SIZE)\n",
    "test_bn_ds_batched = test_bn_ds.batch(BATCH_SIZE, drop_remainder= DROP_REMAINDER)\n",
    "print(test_bn_ds)\n",
    "decoder_1.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss={'label':keras.losses.MeanAbsoluteError()})\n",
    "features_list = [layer.output for layer in encoder.layers]\n",
    "#print(features_list)\n",
    "decoder_1.evaluate(test_bn_ds, verbose=0, steps = STEP_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 2.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 3.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 4.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 5.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 6.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 7.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 8.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 9.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 10.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "[array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTrying to map the train_ds in such a way that the input is replaced by the output of the bottleneck\\nCurrently the fact that predict returns unbatched results appears to be the problem\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def improved_stepwise_bn(model, test_ds, check_vars, repetitions):\n",
    "    orig_l_loss = model.evaluate(test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    mean_value_array = get_column_mean_of_batched_ds(test_ds, \"encoded_snapshots\")\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            m_col_test_ds = test_ds.map(TakeColumnMean(variable_nr, mean_value_array[variable_nr],BOTTLENECK_SIZE))\n",
    "            # calculate the different losses with the new dataset\n",
    "            m_col_l_loss = model.evaluate(m_col_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,m_col_l_loss-orig_l_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    print(meta_loss_list)\n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "\n",
    "loss_list = improved_stepwise_bn(decoder_1, test_bn_ds, range(2), 10)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Trying to map the train_ds in such a way that the input is replaced by the output of the bottleneck\n",
    "Currently the fact that predict returns unbatched results appears to be the problem\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(loss_list)\n",
    "plot_input_importance(loss_list,0,\"Stepwise_bn\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.172 -0.771]]\n",
      "[[ 0.172 -0.771]]\n"
     ]
    }
   ],
   "source": [
    "# accessing the output of all layers\n",
    "\n",
    "features_list = [layer.output for layer in encoder.layers]\n",
    "#print(features_list)\n",
    "feat_extraction_model = keras.Model(inputs=encoder.input, outputs=features_list[-1])\n",
    "\n",
    "img = np.random.random((1,10)).astype('float32')\n",
    "print(encoder(img).numpy())\n",
    "extracted_features = feat_extraction_model(img)\n",
    "print(extracted_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-19847f6f7487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# with a Sequential model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m output = K.function([model.layers[0].input],\n\u001b[0m\u001b[1;32m      6\u001b[0m                     [model.layers[3].output])\n\u001b[1;32m      7\u001b[0m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "example_batch, label_batch = next(iter(train_ds))    \n",
    "\n",
    "\n",
    "# with a Sequential model\n",
    "output = K.function([model.layers[0].input],\n",
    "                    [model.layers[3].output])\n",
    "layer_output = output(example_batch)[0]\n",
    "#print(output)\n",
    "print(example_batch[0][:2])\n",
    "print(layer_output[0])\n",
    "print(label_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_shuffled_columns_from_batched_ds(dataset, key):\n",
    "    # reconstructs the snapshot list based on the batched dataset that is given\n",
    "    # transposes the dataset to have easy access to the columns\n",
    "    # shuffles each column separately\n",
    "    # returns the array back to its orriginal shape with all columns appearing in new permutations\n",
    "    reconstructed_list = np.concatenate(np.array([batch[key].numpy() for batch, label in dataset]))\n",
    "    reconstructed_list = np.transpose(reconstructed_list)\n",
    "    for column_nr in range(len(reconstructed_list)):\n",
    "        reconstructed_list[column_nr] = shuffle(reconstructed_list[column_nr])\n",
    "    reconstructed_list\n",
    "    return reconstructed_list\n",
    "\n",
    "# modify original numpy arrays, generate new datasets and use that for the comparison \n",
    "def input_perturbation_efficiently(model, test_ds, snapshot_list, snapshot_label_list, perturbation, check_vars, repetitions):\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds, verbose=0, steps= 1000)\n",
    "    meta_loss_list = []\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            #print(snapshot_list)\n",
    "            perturbed_snapshot_list = snapshot_list.copy()\n",
    "            # generates random perturbation scaling array, with values uniformly distributed around 1 \n",
    "            # ranging from 1 - perturbation to 1 + perturbation\n",
    "            rand_array = (np.random.rand(len(snapshot_list), 1)-0.5)*(2*perturbation)+1\n",
    "            # multiply corresponding column of the dataset with perturbation scaling array\n",
    "            perturbed_snapshot_list[:,variable_nr] = perturbed_snapshot_list[:,variable_nr]*rand_array[:,0]\n",
    "            # make a new perturbed Dataset to feed into the previously trained model\n",
    "            perturbed_ds = tf.data.Dataset.from_tensor_slices(({\"input_snapshots\": perturbed_snapshot_list},\n",
    "                                            {\"label\":snapshot_label_list, \n",
    "                                             \"reconstruction\":snapshot_list})).shuffle(DATASET_SIZE)\n",
    "            perturbed_test_ds = perturbed_ds.skip(TRAIN_SIZE).batch(BATCH_SIZE)\n",
    "            # calculate the different losses with the new dataset\n",
    "            pert_t_loss, pert_l_loss, pert_r_loss = model.evaluate(perturbed_test_ds, verbose=0, steps = 1000)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,pert_t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,pert_l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,pert_r_loss-orig_r_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "    \n",
    "    \n",
    "def input_perturbation_most_efficient(model, test_ds, perturbation, check_vars, repetitions):\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            perturbed_test_ds = test_ds.map(PerturbDataset(variable_nr, perturbation))\n",
    "            # calculate the different losses with the new dataset\n",
    "            pert_t_loss, pert_l_loss, pert_r_loss = model.evaluate(perturbed_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,pert_t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,pert_l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,pert_r_loss-orig_r_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "    \n",
    "def improved_stepwise(model, test_ds, check_vars, repetitions):\n",
    "    if repetitions > 1:\n",
    "        \"Evaluation occurs on the basis of all batches of size BATCH_SIZE, thereby yielding a reliably result even at only one repetition.\"\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    mean_value_array = get_column_mean_of_batched_ds(test_ds)\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        test_ds_list = []\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            m_col_test_ds = test_ds.map(TakeColumnMean(variable_nr, mean_value_array[variable_nr],DIMENSIONS))\n",
    "            test_ds_list.append(m_col_test_ds)\n",
    "            # calculate the different losses with the new dataset\n",
    "            m_col_t_loss, m_col_l_loss, m_col_r_loss = model.evaluate(m_col_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,m_col_t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,m_col_l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,m_col_r_loss-orig_r_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    return np.array(sum(meta_loss_list)/repetitions), test_ds_list   \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\"\"\"encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(3)(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
    "x = keras.layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = keras.layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = keras.layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = keras.layers.UpSampling2D(3)(x)\n",
    "x = keras.layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = keras.layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
    "autoencoder.summary()\"\"\"\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
