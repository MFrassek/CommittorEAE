{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from copy import deepcopy \n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import time\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLUMN_NAMES = [\"dim1\", \"dim2\", \"dim3\", \"dim4\", \n",
    "#                \"dim5\", \"dim6\", \"dim7\", \"dim8\", \n",
    "#                \"dim9\", \"dim10\", \"label\"]\n",
    "#LABEL_NAME = \"label\"\n",
    "#INPUT_NAMES = list(COLUMN_NAMES)\n",
    "#INPUT_NAMES.remove(LABEL_NAME)\n",
    "trajectory_list = pickle.load(open(\"N-Dim_Doublewell/trajectory_list.p\", \"rb\"))\n",
    "trajectory_label_list = pickle.load(open(\"N-Dim_Doublewell/trajectory_label_list.p\", \"rb\"))\n",
    "BATCH_SIZE = 64\n",
    "#SHUFFLE_BUFFER_SIZE = 1000000\n",
    "CORES_USED = 3\n",
    "DIMENSIONS = 10\n",
    "# sets a random seed for reproducibility of the shuffling process\n",
    "SEED = 5\n",
    "OFFSET = 5\n",
    "DROP_REMAINDER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional section can be used for generation of present/future pairs\n",
    "def generate_offset_snapshot_list(trajectory_list, offset):\n",
    "    # Takes in a list or np.array of trajectories and an offset value and generates two np.arrays with respective new versions\n",
    "    # of the trajectories. \n",
    "    # present_trajectory_list contains all snapshots of the trajectories excluding\n",
    "    # the last n (speficified by offset) of each.\n",
    "    # future_trajectory_list contains all snapshots of the trajectories excluding\n",
    "    # the first n (specified by offset) of each.\n",
    "    # Consequently the both lists can be used as input and desired output of an autoencoder to\n",
    "    # train for future predictive variables.\n",
    "    present_trajectory_list = np.array([trajectory[:-offset] for trajectory in trajectory_list])  \n",
    "    #truncated_present_trajectory_list = \n",
    "    future_trajectory_list = np.array([trajectory[offset:] for trajectory in trajectory_list])\n",
    "    return present_trajectory_list, future_trajectory_list\n",
    "\n",
    "def get_snapshot_and_label_list(trajectory_list, trajectory_label_list, offset = 0, future = False, progress_label = False):\n",
    "    # takes in a list of trajectories and corresponding labels and generates concatenated lists of snapshots, \n",
    "    # snapshot label and snapshot progress labels\n",
    "    # can be used for present/future trajcetory lists by use or offset (same as used for generation of the list)\n",
    "    # and future = True for the future trajectory list\n",
    "    snapshot_list = []\n",
    "    snapshot_label_list = []\n",
    "    for trajectory_nr in range(len(trajectory_list)):\n",
    "        trajectory = trajectory_list[trajectory_nr]\n",
    "        trajectory_label = trajectory_label_list[trajectory_nr]\n",
    "        for snapshot_nr in range(len(trajectory)):\n",
    "            snapshot_list.append(trajectory[snapshot_nr])\n",
    "            if progress_label == False:\n",
    "                snapshot_label_list.append(trajectory_label)\n",
    "            else:\n",
    "                # Calculates the progress along the path for AB paths. If the path label is 1 or 0,\n",
    "                # all snapshot are assigned the same label. If the path label is different (e.g. 0.5),\n",
    "                # indicating a sucessfull transition a progress along the snapshots is calculated based on\n",
    "                # the position within the trajectory and the total trajectory length.\n",
    "                # For present/future lists, the offset needs to be taken into account in the denominator\n",
    "                # If the dataset is a future variant of an offset trajectory list the progress label \n",
    "                # needs to additionally take the offset into account in the nominator.\n",
    "                if trajectory_label == 0.0 or trajectory_label == 1.0:\n",
    "                    snapshot_label_list.append(trajectory_label)\n",
    "                else:\n",
    "                    if future == True:\n",
    "                        snapshot_label_list.append((snapshot_nr + offset)/(len(trajectory) - 1.0 + offset))\n",
    "                    else:\n",
    "                        snapshot_label_list.append(snapshot_nr/(len(trajectory)-1.0 + offset))\n",
    "    return np.array(snapshot_list), np.array(snapshot_label_list)\n",
    "\n",
    "def show_batch(dataset):\n",
    "    for batch, label in dataset.take(1):\n",
    "        for key, value in batch.items():\n",
    "            print(\"{:20s}: {}\".format(key,value.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snapshot_list, snapshot_label_list = get_snapshot_and_label_list(trajectory_list, trajectory_label_list)\n",
    "\n",
    "# Sets a split size for train and test data set\n",
    "#DATASET_SIZE = len(snapshot_label_list)\n",
    "#TRAIN_SIZE = int(DATASET_SIZE * 0.7)\n",
    "SPLIT_RATIO = 0.7\n",
    "BOTTLENECK_SIZE = 2\n",
    "LABEL_LOSS_WEIGHT = 1.0\n",
    "RECONSTRUCTION_LOSS_WEIGHT = 1.0\n",
    "INPUT_NAME = \"input_snapshots\"\n",
    "OUTPUT_NAME_1 = \"label\"\n",
    "OUTPUT_NAME_2 = \"reconstruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_train_test_split(trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False):\n",
    "    assert isinstance(split_ratio, float), \"Split ratio needs to be a of type float\"\n",
    "    if offset == 0 or offset == None:\n",
    "        snapshot_list, snapshot_label_list = get_snapshot_and_label_list(trajectory_list, \\\n",
    "                trajectory_label_list, progress_label = progress_label)\n",
    "        snapshot_list, snapshot_label_list = shuffle(snapshot_list, snapshot_label_list)\n",
    "        train_size = int(len(snapshot_label_list) * split_ratio)\n",
    "        train_snapshot_list = snapshot_list[:train_size].copy()\n",
    "        test_snapshot_list = snapshot_list[train_size:].copy()\n",
    "        train_snapshot_label_list = snapshot_label_list[:train_size].copy()\n",
    "        test_snapshot_label_list = snapshot_label_list[train_size:].copy()\n",
    "        \n",
    "        return train_snapshot_list, train_snapshot_label_list, test_snapshot_list, test_snapshot_label_list\n",
    "    else:\n",
    "        present_trajectory_list, future_trajectory_list = generate_offset_snapshot_list(trajectory_list, offset)\n",
    "        present_snapshot_list, _ = get_snapshot_and_label_list(\n",
    "                present_trajectory_list, trajectory_label_list, offset)\n",
    "        future_snapshot_list, future_snapshot_label_list = get_snapshot_and_label_list(\n",
    "                future_trajectory_list, trajectory_label_list, offset, future = True, \\\n",
    "                progress_label = progress_label)\n",
    "        present_snapshot_list, future_snapshot_list, future_snapshot_label_list = shuffle(\n",
    "                present_snapshot_list, future_snapshot_list, future_snapshot_label_list)\n",
    "        train_size = int(len(future_snapshot_label_list) * split_ratio)\n",
    "        \n",
    "        train_present_snapshot_list = present_snapshot_list[:train_size].copy()\n",
    "        test_present_snapshot_list = present_snapshot_list[train_size:].copy()\n",
    "        train_future_snapshot_list = future_snapshot_list[:train_size].copy()\n",
    "        test_future_snapshot_list = future_snapshot_list[train_size:].copy()\n",
    "        train_future_snapshot_label_list = future_snapshot_label_list[:train_size].copy()\n",
    "        test_future_snapshot_label_list = future_snapshot_label_list[train_size:].copy()   \n",
    "        return train_present_snapshot_list, train_future_snapshot_list, \\\n",
    "                train_future_snapshot_label_list, test_present_snapshot_list, \\\n",
    "                test_future_snapshot_list, test_future_snapshot_label_list\n",
    "\n",
    "def generate_ds(trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False):\n",
    "    if offset == 0 or offset == None:\n",
    "        train_snapshot_list, train_snapshot_label_list, \\\n",
    "                test_snapshot_list, test_snapshot_label_list = shuffled_train_test_split(\n",
    "                        trajectory_list, trajectory_label_list, split_ratio, offset = 0, progress_label = False)\n",
    "        dataset_size = len(train_snapshot_list) + len(test_snapshot_list)\n",
    "        # generates the dataset by feeding in a tuple, of dictionaries (alternative would be a tuble of lists)\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: train_snapshot_list},\n",
    "                {OUTPUT_NAME_1: train_snapshot_label_list, \n",
    "                OUTPUT_NAME_2: train_snapshot_list})).shuffle(dataset_size)\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: test_snapshot_list},\n",
    "                {OUTPUT_NAME_1: test_snapshot_label_list, \n",
    "                OUTPUT_NAME_2: test_snapshot_list})).shuffle(dataset_size)\n",
    "        step_number = int(len(test_snapshot_list)/BATCH_SIZE)\n",
    "        \n",
    "        return dataset_size, step_number, train_ds, test_ds, train_snapshot_list, \\\n",
    "                [], train_snapshot_label_list, test_snapshot_list, \\\n",
    "                [], test_snapshot_label_list\n",
    "    else:\n",
    "        train_snapshot_list, train_future_snapshot_list, train_future_snapshot_label_list, \\\n",
    "                test_snapshot_list, test_future_snapshot_list, test_future_snapshot_label_list = shuffled_train_test_split(\n",
    "                        trajectory_list, trajectory_label_list, split_ratio, offset = offset, \\\n",
    "                        progress_label = False)\n",
    "        dataset_size = len(train_snapshot_list) + len(test_snapshot_list)\n",
    "        # generates the dataset by feeding in a tuple, of dictionaries (alternative would be a tuble of lists)\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: train_snapshot_list},\n",
    "                {OUTPUT_NAME_1: train_future_snapshot_label_list, \n",
    "                OUTPUT_NAME_2: train_future_snapshot_list})).shuffle(dataset_size)\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: test_snapshot_list},\n",
    "                {OUTPUT_NAME_1: test_future_snapshot_label_list, \n",
    "                OUTPUT_NAME_2: test_future_snapshot_list})).shuffle(dataset_size)\n",
    "        step_number = int(len(test_present_snapshot_list)/BATCH_SIZE)\n",
    "    \n",
    "        return dataset_size, step_number, train_ds, test_ds, train_snapshot_list, \\\n",
    "                train_future_snapshot_list, train_future_snapshot_label_list, test_snapshot_list, \\\n",
    "                test_future_snapshot_list, test_future_snapshot_label_list\n",
    "                \n",
    "\n",
    "DATASET_SIZE, STEP_NUMBER, train_ds, test_ds, train_snapshot_list, train_future_snapshot_list, \\\n",
    "        train_snapshot_label_list, test_snapshot_list, test_future_snapshot_list, \\\n",
    "        test_snapshot_label_list = generate_ds(trajectory_list, \\\n",
    "                trajectory_label_list, SPLIT_RATIO, offset = 0, progress_label = False)\n",
    "\n",
    "TEST_SIZE = len(test_snapshot_list)\n",
    "# if remainder is dopped during batching, the TEST_SIZE is reduced by the size of the last incomplete batch\n",
    "if DROP_REMAINDER == True:\n",
    "    TEST_SIZE = TEST_SIZE - (TEST_SIZE % BATCH_SIZE)\n",
    "\n",
    "train_ds_batch = train_ds.batch(BATCH_SIZE, drop_remainder=DROP_REMAINDER)\n",
    "test_ds_batch = test_ds.batch(BATCH_SIZE, drop_remainder=DROP_REMAINDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(DIMENSIONS,),name=INPUT_NAME)\n",
    "x = keras.layers.Dense(DIMENSIONS, activation= 'tanh')(encoder_input)\n",
    "x = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(x)\n",
    "x = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(x)\n",
    "encoder_output = keras.layers.Dense(BOTTLENECK_SIZE, activation='tanh', name='bottleneck')(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name =\"encoder\")\n",
    "#encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(BOTTLENECK_SIZE,), name =\"encoded_snapshots\")\n",
    "\n",
    "x1 = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(decoder_input)\n",
    "x1 = keras.layers.Dense(DIMENSIONS, activation='tanh')(x1)\n",
    "decoder_output_1 = keras.layers.Dense(1, activation='tanh',name=OUTPUT_NAME_1)(x1)\n",
    "decoder_1 = keras.Model(decoder_input, decoder_output_1, name=OUTPUT_NAME_1)\n",
    "#decoder_1.summary()\n",
    "\n",
    "x2 = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(decoder_input)\n",
    "x2 = keras.layers.Dense(DIMENSIONS*2, activation='tanh')(x2)\n",
    "decoder_output_2 = keras.layers.Dense(DIMENSIONS, activation='tanh',name=OUTPUT_NAME_2)(x2)\n",
    "decoder_2 = keras.Model(decoder_input, decoder_output_2, name=OUTPUT_NAME_2)\n",
    "#decoder_2.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(DIMENSIONS,), name=INPUT_NAME)\n",
    "encoded_snaphot = encoder(autoencoder_input)\n",
    "label_snapshot = decoder_1(encoded_snaphot)\n",
    "reconstructed_snapshot = decoder_2(encoded_snaphot)\n",
    "autoencoder = keras.Model(inputs=autoencoder_input, outputs=[label_snapshot,reconstructed_snapshot])\n",
    "\n",
    "model_layout = keras.utils.plot_model(autoencoder, 'multi_input_and_output_model.png', show_shapes=True)\n",
    "display.display(model_layout)\n",
    "#display.display(keras.utils.plot_model(encoder, 'encoder.png', show_shapes=True))\n",
    "#display.display(keras.utils.plot_model(decoder_1, 'decoder_1.png', show_shapes=True))\n",
    "#display.display(keras.utils.plot_model(decoder_2, 'decoder_2.png', show_shapes=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss={OUTPUT_NAME_1:keras.losses.MeanAbsoluteError(),\n",
    "                      OUTPUT_NAME_2: keras.losses.MeanAbsoluteError()},\n",
    "              loss_weights=[LABEL_LOSS_WEIGHT, RECONSTRUCTION_LOSS_WEIGHT])\n",
    "\n",
    "autoencoder_1 = keras.Model(inputs=autoencoder_input, outputs=label_snapshot)\n",
    "autoencoder_1.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss={OUTPUT_NAME_1:keras.losses.MeanAbsoluteError()})\n",
    "\n",
    "autoencoder_2 = keras.Model(inputs=autoencoder_input, outputs=reconstructed_snapshot)\n",
    "autoencoder_2.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss={OUTPUT_NAME_2:keras.losses.MeanAbsoluteError()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2522 steps\n",
      "Epoch 1/3\n",
      "2522/2522 [==============================] - 6s 2ms/step - loss: 0.4551 - label_loss: 0.0569 - reconstruction_loss: 0.3982\n",
      "Epoch 2/3\n",
      "2522/2522 [==============================] - 5s 2ms/step - loss: 0.4380 - label_loss: 0.0415 - reconstruction_loss: 0.3965\n",
      "Epoch 3/3\n",
      "2522/2522 [==============================] - 5s 2ms/step - loss: 0.4357 - label_loss: 0.0400 - reconstruction_loss: 0.3957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffb243c8e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(train_ds_batch,epochs=3)\n",
    "#set back to 10 for proper tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 1ms/step - loss: 0.4295 - label_loss: 0.0337 - reconstruction_loss: 0.3958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4295273302329911, 0.03373921, 0.3957882]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(test_ds_batch, verbose=1, steps = STEP_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_generated_labels(model, x_list, y_list, dimensions, additional_dim_val, x_var_pos, y_var_pos):\n",
    "    assert x_var_pos != y_var_pos, \"x_var_pos and y_var_pos need to differ\"\n",
    "    label_map = []\n",
    "    for x in x_list:\n",
    "        label_current_row = []\n",
    "        for y in y_list:\n",
    "            label_current_row.append(model.predict([[x if x_var_pos == pos_nr else y if \\\n",
    "                    y_var_pos == pos_nr else additional_dim_val for pos_nr in range(dimensions)]])[0][0][0])\n",
    "        label_map.append(label_current_row)\n",
    "    return np.array(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_given_labels(snapshot_list, snapshot_label_list, x_list, y_list, x_var_pos, y_var_pos):\n",
    "    x_nr = len(x_list)\n",
    "    y_nr = len(y_list)\n",
    "    min_x = min(x_list)\n",
    "    max_x = max(x_list)\n",
    "    min_y = min(y_list)\n",
    "    max_y = max(y_list)\n",
    "    # generate a list of lists of lists to store all labels in\n",
    "    label_map = [[[] for y in y_list] for x in x_list]\n",
    "    # sort the labels of each snapshot to the corresponding \"positions\" in the grid (by sorting them in the list)\n",
    "    for snapshot_nr in range(len(snapshot_list)):\n",
    "        x_snap = snapshot_list[snapshot_nr][x_var_pos]\n",
    "        y_snap = snapshot_list[snapshot_nr][y_var_pos]\n",
    "        # int to be able to use for iteration, round to round to closest full number, \n",
    "        # i-min_x to offset to start at 0, /2.0*(x-nr-1) to rescale\n",
    "        x_int = int(round((x_snap - min_x)/2.0*(x_nr-1)))\n",
    "        y_int = int(round((y_snap - min_y)/2.0*(y_nr-1)))\n",
    "        label_map[x_int][y_int].append(snapshot_label_list[snapshot_nr])\n",
    "\n",
    "    for row_ind in range(len(label_map)):\n",
    "        for col_ind in range(len(label_map[row_ind])):\n",
    "            if len(label_map[row_ind][col_ind]) > 0:\n",
    "                label_map[row_ind][col_ind] = np.mean(label_map[row_ind][col_ind])\n",
    "            else:\n",
    "                label_map[row_ind][col_ind] = float('NaN')\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_generated(model, input_type, output_type, x_list, y_list, additional_dim_val, x_var_pos, y_var_pos):\n",
    "    assert x_var_pos != y_var_pos, \"x_var_pos and y_var_pos need to differ\"\n",
    "    if input_type == \"bn\":\n",
    "        dimensions = BOTTLENECK_SIZE\n",
    "    elif input_type == \"snapshot\":\n",
    "        dimensions = DIMENSIONS\n",
    "    else:\n",
    "        assert True, \"input_type needs to be set to 'bn' (bottleneck) or 'snapshot'.\"\n",
    "    if output_type == \"label\":\n",
    "        output_len = 1\n",
    "    elif output_type == \"bn\":\n",
    "        output_len = BOTTLENECK_SIZE\n",
    "    elif output_type == \"snapshot\":\n",
    "        output_len = DIMENSIONS\n",
    "    else:\n",
    "        assert True, \"output_type needs to be set to 'bn' (bottleneck), 'label' or 'snapshot'.\"\n",
    "    output_map = [[] for i in range(output_len)]\n",
    "    for x in x_list:\n",
    "        output_current_row = [[] for i in range(output_len)]\n",
    "        for y in y_list:\n",
    "            prediction = model.predict([[x if x_var_pos == pos_nr else y if \\\n",
    "                    y_var_pos == pos_nr else additional_dim_val for pos_nr in range(dimensions)]])[0]\n",
    "            for i in range(output_len):\n",
    "                output_current_row[i].append(prediction[i])\n",
    "        for i in range(output_len):\n",
    "            output_map[i].append(output_current_row[i])\n",
    "    return np.array(output_map)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 5\n",
    "\n",
    "def make_label_map_figure(mode, mode_var, resolution, dimensions, i_range, j_range, vmin, vmax):\n",
    "    if mode == \"generated\":\n",
    "        model = mode_var[0]\n",
    "        additional_dim_value = mode_var[1]\n",
    "        if model == encoder:\n",
    "            input_type = \"snapshot\"\n",
    "            output_type = \"bn\"\n",
    "            suptitle = \"Predicted bottlenecks depending on snapshot input\"\n",
    "        elif model == decoder_1:\n",
    "            input_type = \"bn\"\n",
    "            output_type = \"label\"\n",
    "            suptitle = \"Predicted labels on bottleneck input\"\n",
    "        elif model == decoder_2:\n",
    "            input_type = \"bn\"\n",
    "            output_type = \"snapshot\"\n",
    "            suptitle = \"Predicted snapshots depending on bottleneck input\"\n",
    "        elif model == autoencoder_1:\n",
    "            input_type = \"snapshot\"\n",
    "            output_type = \"label\"\n",
    "            suptitle = \"Predicted labels depending on snapshot input\"\n",
    "        elif model == autoencoder_2:\n",
    "            input_type = \"snapshot\"\n",
    "            output_type = \"snapshot\"\n",
    "            suptitle = \"Predicted snapshots depending on snapshot input\"\n",
    "    elif mode == \"given\":\n",
    "        snapshot_list = mode_var[0]\n",
    "        snapshot_label_list = mode_var[1]\n",
    "\n",
    "    meta_label_map = []            \n",
    "    for i in range(i_range):\n",
    "        meta_label_map.append([])   \n",
    "        for j in range(j_range):\n",
    "            meta_label_map[i].append([])\n",
    "            if j > i:\n",
    "                print(i, j)\n",
    "                if mode == \"generated\":\n",
    "                    label_map = map_generated(model, input_type, output_type, \\\n",
    "                        np.linspace(-1,1,resolution), np.linspace(-1,1,resolution), additional_dim_value, i, j)\n",
    "                elif mode == \"given\":\n",
    "                    label_map = map_given_labels(snapshot_list, \\\n",
    "                        snapshot_label_list, np.linspace(-1,1,resolution), np.linspace(-1,1,resolution), i, j)\n",
    "                    suptitle = \"Given labels depending on snapshot input\"\n",
    "                meta_label_map[i][j].append(label_map)\n",
    "    # gets output len by simply taking the length of the last generated label_map\n",
    "    for k in range(len(label_map)):\n",
    "        print(k)\n",
    "        fig, axs = plt.subplots(i_range, j_range)\n",
    "        fig.suptitle(suptitle)                \n",
    "        for i in range(i_range):\n",
    "            for j in range(j_range):\n",
    "                axs[i][j].tick_params(\n",
    "                    axis='both',\n",
    "                    which='both',\n",
    "                    bottom=False,\n",
    "                    top=False,\n",
    "                    labelbottom=False,\n",
    "                    left = False,\n",
    "                    labelleft= False)  \n",
    "        for i in range(i_range):  \n",
    "            for j in range(j_range):\n",
    "                if j > i:\n",
    "                    im = axs[j][i].imshow(np.transpose(meta_label_map[i][j][0][k])[::-1], cmap='coolwarm', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "                    if input_type == \"snapshot\":\n",
    "                        if j == j_range - 1:\n",
    "                            axs[j][i].set_xlabel(\"x{}\".format(i))\n",
    "                        if i == 0:\n",
    "                            axs[j][i].set_ylabel(\"x{}\".format(j))\n",
    "                    elif input_type == \"bn\":\n",
    "                        if j == j_range - 1:\n",
    "                            axs[j][i].set_xlabel(\"b{}\".format(i))\n",
    "                        if i == 0:\n",
    "                            axs[j][i].set_ylabel(\"b{}\".format(j))\n",
    "                else:\n",
    "                    axs[j][i].axis(\"off\")\n",
    "        cax,kw = mpl.colorbar.make_axes([ax for ax in axs])\n",
    "        plt.colorbar(im, cax=cax, **kw)\n",
    "        plt.savefig(\"Map_{}_res{}_min{}_max{}_output_node_{}\".format(mode, resolution, vmin, vmax, k)) \n",
    "        plt.show()\n",
    "\n",
    "#make_label_map_figure(mode = \"given\", mode_var = [test_snapshot_list, test_snapshot_label_list], \\\n",
    "#        resolution = RESOLUTION, dimensions = DIMENSIONS, i_range = 10, j_range = 10, \\\n",
    "#        vmin = 0, vmax = 1)\n",
    "\n",
    "#make_label_map_figure(mode = \"generated\", mode_var = [autoencoder_1, 0], \\\n",
    "#        resolution = RESOLUTION, dimensions = DIMENSIONS, i_range = 10, j_range = 10, \\\n",
    "#        vmin = 0, vmax = 1)\n",
    "\n",
    "#make_label_map_figure(mode = \"generated\", mode_var = [autoencoder_2, 0], \\\n",
    "#        resolution = RESOLUTION, dimensions = DIMENSIONS, i_range = 10, j_range = 10, \\\n",
    "#        vmin = -1, vmax = 1)\n",
    "\n",
    "#make_label_map_figure(mode = \"generated\", mode_var = [encoder, 0], \\\n",
    "#        resolution = RESOLUTION, dimensions = DIMENSIONS, i_range = 10, j_range = 10, \\\n",
    "#        vmin = -1, vmax = 1)\n",
    "\n",
    "#make_label_map_figure(mode = \"generated\", mode_var = [decoder_1, 0], \\\n",
    "#        resolution = RESOLUTION, dimensions = DIMENSIONS, i_range = 10, j_range = 10, \\\n",
    "#        vmin = 0, vmax = 1)\n",
    "\n",
    "#make_label_map_figure(mode = \"generated\", mode_var = [decoder_1, 0], \\\n",
    "#        resolution = RESOLUTION, dimensions = DIMENSIONS, i_range = 10, j_range = 10, \\\n",
    "#        vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DROP_REMAINDER = True, TEST_SIZE will not fit the size of the snapshot_list anymore\n",
    "# either remove the update of TEST_SIZE, adapt test_snapshot_list, or replace TEST_SIZE with a different value\n",
    "\n",
    "def perturb_snapshot_list(snapshot_list, mod_along, perturbation):\n",
    "    transposed_list = np.transpose(deepcopy(snapshot_list))\n",
    "    rand_array = np.random.uniform(1 - perturbation, 1 + perturbation, TEST_SIZE)\n",
    "    transposed_list[mod_along] = np.transpose(snapshot_list)[mod_along] * rand_array\n",
    "    return np.transpose(transposed_list)\n",
    "\n",
    "def set_mean_snapshot_list(snapshot_list, mod_along, column_mean):\n",
    "    transposed_list = np.transpose(deepcopy(snapshot_list))\n",
    "    transposed_list[mod_along] = column_mean\n",
    "    return np.transpose(transposed_list)\n",
    "\n",
    "def HIPR_snapshot_list(snapshot_list, mod_along, min_value, max_value):\n",
    "    transposed_list = np.transpose(deepcopy(snapshot_list))\n",
    "    rand_array = np.random.uniform(min_value, max_value, TEST_SIZE)\n",
    "    transposed_list[mod_along] = rand_array\n",
    "    return np.transpose(transposed_list)\n",
    "\n",
    "def shuffle_snapshot_list(snapshot_list, mod_along):\n",
    "    # since independent runs should use different shuffled lists, nothing is passed down\n",
    "    transposed_list = np.transpose(deepcopy(snapshot_list))\n",
    "    transposed_list[mod_along] = shuffle(transposed_list[mod_along])\n",
    "    return np.transpose(transposed_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: perturb\n",
      "Repetition 1.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "\tPerturbing variable 2.\n",
      "Mode: mean\n",
      "Repetition 1.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "\tPerturbing variable 2.\n",
      "Mode: HIPR\n",
      "Repetition 1.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "\tPerturbing variable 2.\n",
      "Mode: shuffle\n",
      "Repetition 1.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "\tPerturbing variable 2.\n"
     ]
    }
   ],
   "source": [
    "def input_importance(mode, mode_var, model, test_ds, test_snapshot_list, test_snapshot_label_list, \\\n",
    "                     test_2_snapshot_list, check_vars, repetitions):\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    # initialization dependent on the mode\n",
    "    if mode == \"perturb\":\n",
    "        perturbation = mode_var\n",
    "    elif mode == \"mean\":\n",
    "        if repetitions > 1:\n",
    "            \"Evaluation occurs on the basis of all batches of size BATCH_SIZE, thereby yielding a reliably result even at only one repetition.\"\n",
    "        mean_value_array = mode_var\n",
    "    elif mode == \"HIPR\":\n",
    "        min_value = mode_var[0]\n",
    "        max_value = mode_var[1]\n",
    "    elif mode == \"shuffle\":\n",
    "        pass\n",
    "        \n",
    "    print(\"Mode: {}\".format(mode))\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            # generating modified snapshot_lists\n",
    "            if mode == \"perturb\":\n",
    "                mod_test_snapshot_list = perturb_snapshot_list(test_snapshot_list, variable_nr, perturbation)\n",
    "            elif mode == \"mean\":\n",
    "                mod_test_snapshot_list = set_mean_snapshot_list(test_snapshot_list, variable_nr, mean_value_array[variable_nr])\n",
    "            elif mode == \"HIPR\":\n",
    "                mod_test_snapshot_list = HIPR_snapshot_list(test_snapshot_list, variable_nr, min_value, max_value)\n",
    "            elif mode == \"shuffle\":\n",
    "                mod_test_snapshot_list = shuffle_snapshot_list(test_snapshot_list, variable_nr)\n",
    "                \n",
    "            mod_test_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: mod_test_snapshot_list},\n",
    "                    {OUTPUT_NAME_1: test_snapshot_label_list, \n",
    "                OUTPUT_NAME_2: test_2_snapshot_list})).shuffle(DATASET_SIZE).batch(BATCH_SIZE, drop_remainder=DROP_REMAINDER)\n",
    "            # calculate the different losses with the new dataset\n",
    "            t_loss, l_loss, r_loss = model.evaluate(mod_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,r_loss-orig_r_loss))\n",
    "        # average over the loss lists\n",
    "        # negative increases of loss are set to zero\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    \n",
    "    total_normalized_losses = np.transpose([sum(np.transpose(sum(meta_loss_list)))])\n",
    "    # sets value to 1 if all the losses add up to 0 and would cause a divide by zero error\n",
    "    total_normalized_losses = np.array([value[0] if value != 0 else 1 for value in total_normalized_losses])\n",
    "    #print(np.array(sum(meta_loss_list)/repetitions))\n",
    "    return sum(meta_loss_list)/np.transpose([total_normalized_losses])\n",
    "\n",
    "def plot_input_importance(loss_list, loss_type, name):\n",
    "    variable_nr = len(loss_list[0])\n",
    "    plt.bar(range(variable_nr),loss_list[loss_type])\n",
    "    if loss_type == 0:\n",
    "        loss_type = \"total\"\n",
    "    elif loss_type == 1:\n",
    "        loss_type = OUTPUT_NAME_1\n",
    "    elif loss_type == 2:\n",
    "        loss_type = OUTPUT_NAME_2\n",
    "    plt.savefig(\"{}_{}.png\".format(name,loss_type))        \n",
    "    plt.close()\n",
    "    \n",
    "#perturbed_loss_list = input_importance(\"perturb\", 0.5, autoencoder, test_ds_batch, test_snapshot_list, \\\n",
    "#        test_snapshot_label_list, test_snapshot_list, range(3), 1)\n",
    "#plot_input_importance(perturbed_loss_list,1,\"Perturb_0.5\")\n",
    "#mean_loss_list = input_importance(\"mean\", np.mean(test_snapshot_list, axis = 0), autoencoder, test_ds_batch, test_snapshot_list, \\\n",
    "#        test_snapshot_label_list, test_snapshot_list, range(3), 1)\n",
    "#plot_input_importance(mean_loss_list,1,\"Mean\")\n",
    "#hipr_loss_list = input_importance(\"HIPR\", [-0.9,0.9], autoencoder, test_ds_batch, test_snapshot_list, \\\n",
    "#        test_snapshot_label_list, test_snapshot_list, range(3), 1)\n",
    "#plot_input_importance(hipr_loss_list,1,\"HIPR_range[-0.9,0.9]\")\n",
    "#shuffle_loss_list = input_importance(\"shuffle\", None, autoencoder, test_ds_batch, test_snapshot_list, \\\n",
    "#        test_snapshot_label_list, test_snapshot_list, range(3), 1)\n",
    "#plot_input_importance(shuffle_loss_list,1,\"Shuffle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 2.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 3.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 4.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 5.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 6.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 7.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 8.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 9.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "Repetition 10.\n",
      "\tPerturbing variable 0.\n",
      "\tPerturbing variable 1.\n",
      "[array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]]), array([[0, 0]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTrying to map the train_ds in such a way that the input is replaced by the output of the bottleneck\\nCurrently the fact that predict returns unbatched results appears to be the problem\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~\n",
    "# Cleaned until here\n",
    "#~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#Here be Dragons\n",
    "def improved_stepwise_bn(model, test_ds, check_vars, repetitions):\n",
    "    orig_l_loss = model.evaluate(test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    mean_value_array = get_column_mean_of_batched_ds(test_ds, \"encoded_snapshots\")\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            m_col_test_ds = test_ds.map(TakeColumnMean(variable_nr, mean_value_array[variable_nr],BOTTLENECK_SIZE))\n",
    "            # calculate the different losses with the new dataset\n",
    "            m_col_l_loss = model.evaluate(m_col_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,m_col_l_loss-orig_l_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    print(meta_loss_list)\n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "\n",
    "loss_list = improved_stepwise_bn(decoder_1, test_bn_ds, range(2), 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.172 -0.771]]\n",
      "[[ 0.172 -0.771]]\n"
     ]
    }
   ],
   "source": [
    "# accessing the output of all layers\n",
    "\n",
    "features_list = [layer.output for layer in encoder.layers]\n",
    "#print(features_list)\n",
    "feat_extraction_model = keras.Model(inputs=encoder.input, outputs=features_list[-1])\n",
    "\n",
    "img = np.random.random((1,10)).astype('float32')\n",
    "print(encoder(img).numpy())\n",
    "extracted_features = feat_extraction_model(img)\n",
    "print(extracted_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-19847f6f7487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# with a Sequential model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m output = K.function([model.layers[0].input],\n\u001b[0m\u001b[1;32m      6\u001b[0m                     [model.layers[3].output])\n\u001b[1;32m      7\u001b[0m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "example_batch, label_batch = next(iter(train_ds))    \n",
    "\n",
    "\n",
    "# with a Sequential model\n",
    "output = K.function([model.layers[0].input],\n",
    "                    [model.layers[3].output])\n",
    "layer_output = output(example_batch)[0]\n",
    "#print(output)\n",
    "print(example_batch[0][:2])\n",
    "print(layer_output[0])\n",
    "print(label_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(label_map, title, x_name, y_name, vmin, vmax):\n",
    "    plt.close()\n",
    "    # use transpose to rotate the map into the right orientation\n",
    "    # use [::-1] to invert the new y_axis\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(np.transpose(label_map)[::-1], cmap='coolwarm', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    #plt.axis('off')\n",
    "    plt.tick_params(\n",
    "        axis='both',\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False, # labels along the bottom edge are off\n",
    "        left = False,\n",
    "        labelleft= False)     \n",
    "    plt.xlabel(\"{}\".format(x_name))\n",
    "    plt.ylabel(\"{}\".format(y_name))\n",
    "    plt.savefig(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if j > i:\n",
    "            print(i, j)\n",
    "            label_map_generated = map_generated_labels(autoencoder, \\\n",
    "                    np.linspace(-1,1,RESOLUTION), np.linspace(-1,1, RESOLUTION), DIMENSIONS, 0, i, j)\n",
    "            plot_heatmap(label_map_generated, \"{}{}_21_label_map_generated.png\".format(i,j), \\\n",
    "                    \"x{}\".format(i), \"x{}\".format(j), 0, 1)\n",
    "            label_map_given = map_given_labels_efficiently(train_snapshot_list, \\\n",
    "                    train_snapshot_label_list, np.linspace(-1,1,RESOLUTION), np.linspace(-1,1,RESOLUTION), i, j)\n",
    "            plot_heatmap(label_map_given, \"{}{}_21_label_map_given.png\".format(i,j), \\\n",
    "                    \"x{}\".format(i), \"x{}\".format(j), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_generated_bottleneck(model, x_list, y_list, dimensions, additional_dim_val, x_var_pos, y_var_pos, bottlenek_node_nr):\n",
    "    assert x_var_pos != y_var_pos, \"x_var_pos and y_var_pos need to differ\"\n",
    "    output_map = [[] for i in range(bottlenek_node_nr)]\n",
    "    for x in x_list:\n",
    "        output_current_row = [[] for i in range(bottlenek_node_nr)]\n",
    "        for y in y_list:\n",
    "            prediction = model.predict([[x if x_var_pos == pos_nr else y if \\\n",
    "                    y_var_pos == pos_nr else additional_dim_val for pos_nr in range(dimensions)]])[0]\n",
    "            for subrow_nr in range(bottlenek_node_nr):\n",
    "                output_current_row[subrow_nr].append(prediction[subrow_nr])      \n",
    "        for subarray_nr in range(bottlenek_node_nr):\n",
    "            output_map[subarray_nr].append(output_current_row[subarray_nr])\n",
    "    return np.array(output_map)\n",
    "\n",
    "bottleneck_map_generated = map_generated_bottleneck(encoder, \\\n",
    "        np.linspace(-1,1,RESOLUTION), np.linspace(-1,1, RESOLUTION), DIMENSIONS, 0, 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(bottleneck_map_generated[0], \"{}{}_21_bottleneck_map_generated_b0.png\".format(0,1), \"x0\", \"x1\", -1, 1)\n",
    "plot_heatmap(bottleneck_map_generated[1], \"{}{}_21_bottleneck_map_generated_b1.png\".format(0,1), \"x0\", \"x1\", -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD1CAYAAACIsbNlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAHi0lEQVR4nO3dz4udVx3H8e+5M1OnRqlWG4QWU0EJbtSdP3Cj7kTBhQgFfyxc6X+imwoiQncVFwrduHHjoiAN1FXxB1WsCGnFTQW1KqaaucdFphDTSe7zzDxnbuZzX69V5s6T85yUvPPMJN+e23rvBeRYbXsDwLJEDWFEDWFEDWFEDWH2Ryz6UNvrl+tgxNLAsT/U63/pvT9y5+tDor5cB/Xk3pURSwPHPn/0++snve7Lbwgjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggjaggz5Iwy4P+tDtryix7d5V7L3wnYJlFDGFFDGFFDGFFDGFFDGFFDGFFDGFFDmDETZW35CZr1f/ui67F7hkx13Yc8qSGMqCGMqCGMqCGMqCGMqCGMqCGMqCGMqCGMqCHMhTl4cFdG/OCsPKkhjKghjKghjKghjKghjKghjKghjKghjKghzIWZKINd0aZOT944+WVPaggjaggjaggjaggjaggjaggjaggjaggjaggz6K1s2/SpmC3q3h53p1yE35NL8KSGMKKGMKKGMKKGMKKGMKKGMKKGMKKGMKKGMKKGMEPGRFurWu0vO5K3vrn8SOeujA2yfUv3cM97ndudgHMhaggjaggjaggjaggjaggjaggjaggjaggz6ODB5ae19iau5zBB7kfnOb3oSQ1hRA1hRA1hRA1hRA1hRA1hRA1hRA1hRA1hxpxRtqrae3DZPy8mT4oNOAtqxPlo3L/O8zyxk5x1+syTGsKIGsKIGsKIGsKIGsKIGsKIGsKIGsKIGsKIGsIMGhNtdXBp89Lr9Xr6og9Ou2zEwYN7E68zTpphxJiogweBUzt11K21p5bcCLCMe36N3Fp7+G6fqqrPLr8d4Kw2feP7alVdr1sRv6Eff3x51KaA09sU9R+r6jO995fv/ERr7ZUxWwLOYtP31N+pqnfe5XPfXngvwALu+aTuvX+vqqq1dlhV36yqT9atL7+fq6rvD98dMNvUf6f+QVX9o6q+e/zxE8evfWnEpoDTmxr11d77h2/7+NnW2i9HbAg4m6lRv9Ba+1jv/fmqqtbaR6vq2t0unjpR1o+Wn8Dq6+lrrhe+/4hfD+ev7S0//bUasObdbPp36l/Xre+hD6rqq621l48/vlJVL47fHjDXpsfp585lF8BiNv3t9/Xz2giwDP9DB4QRNYQRNYQRNYQRNYQRNYQRNYQZc/Dg3qoOHzrceF2fcfDg1BHM9Ywx0cn3nrhmP5pxkOLClh55vUiWHsFse8s/69pq+h5XM6498eef6WcD9x1RQxhRQxhRQxhRQxhRQxhRQxhRQxhRQ5ghE2Wr/VVdeveljdfNOSRw6vTZiIMHR9x7zrVTmChbzpzprznXTl/zbM9aT2oII2oII2oII2oII2oII2oII2oII2oII2oIM2SibO+B/Xr7Y+/aeF2/eTR5zfXEa0dMdW1zomzEvdMsPdU1Z6Jr6r3nTamZKANuI2oII2oII2oII2oII2oII2oII2oII2oII2oIM2hM9KDeduXRjdf1o+ljopOvnfH2uFNHT6tPfBvdGWOvc/Y5RZ+4x6p5byF8EZx1rPJN67UZY6cT721MFDg1UUMYUUMYUUMYUUMYUUMYUUMYUUMYUUOYIRNldXhY+++/uvGytr45fc3JE2Uzpromrjl5AmvOvaceFNgHTH+NOKRw6j7bFp8jU6e65uxxxJpzJtpO4EkNYUQNYUQNYUQNYUQNYUQNYUQNYUQNYUQNYYZMlB098Nb6+5WPbLxuNWMCa9WnXdtmTGC1qfefeP5XqwH3nrrenF/3jPPMLoJ+xgmsN693ftNfZ77/CTypIYyoIYyoIYyoIYyoIYyoIYyoIYyoIYyoIYyoIcyQMdEb/bB+e/TBjdfttenjim3itW01fc3V3sL3ruV/PZPXm3Fv7q3XgNHPvvyad+NJDWFEDWFEDWFEDWFEDWFEDWFEDWFEDWFEDWGGTJT968aqnn/xLYuuOeB8t1oF/ZHWRhyAF3ZA4a4I+m0NVIka4ogawogawogawogawogawogawogawogawgwZE/3na/+uaz/73cbr1uvlxxD7evr7NC9+7wFjlT3sv9H6AoyergaM3LZznEn2pIYwooYwooYwooYwooYwooYwooYwooYwooYwbcQUVGvt1aq6vvjCwO2u9N4fufPFIVED2+PLbwgjaggjaggj6h3UWnu8tfabE15/X2vtF621l1prP26tPbCN/XE2ouZ236qqJ3vvH6iqv1bV17e8H05B1Ltrv7X2dGvtV621Z1prl6rq01X1zPHnn66qL2xve5yWqHfX1ap6qvf+oap6raq+UVV/673fPP78n6rq0W1tjtMT9e56pfd+7fjHP6yqT51wjSGGC0jUu+vOYP9TVe9orb1xbt1jVfXn890SSxD17npva+3jxz9+oqqeq6pnq+qLx699rap+so2NcTbGRHdQa+3xqvppVf28qj5RVS9V1Veq6j1V9aOqeriqXqiqL/feX9/OLjktUUMYX35DGFFDGFFDGFFDGFFDGFFDGFFDmP8BqOhW25TV/O0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_generated_label_from_bn(model, x_list, y_list, dimensions, additional_dim_val, x_var_pos, y_var_pos):\n",
    "    assert x_var_pos != y_var_pos, \"x_var_pos and y_var_pos need to differ\"\n",
    "    label_map = []\n",
    "    for x in x_list:\n",
    "        label_current_row = []\n",
    "        for y in y_list:\n",
    "            label_current_row.append(model.predict([[x if x_var_pos == pos_nr else y \\\n",
    "                    if y_var_pos == pos_nr else additional_dim_val for pos_nr in range(dimensions)]])[0][0])\n",
    "        label_map.append(label_current_row)\n",
    "    return np.array(label_map)\n",
    " \n",
    "label_map_from_bn = map_generated_label_from_bn(decoder_1, np.linspace(-1,1,RESOLUTION), \\\n",
    "        np.linspace(-1,1, RESOLUTION), BOTTLENECK_SIZE, 0, 0, 1)\n",
    "plot_heatmap(label_map_from_bn, \"{}{}_21_label_map_from_bn.png\".format(0,1), \"b0\", \"b1\", 0, 1)\n",
    "\n",
    "# misusing map generated_bottleneck here, since it has the same functionality of generating an array of maps for each output\n",
    "reconstructed_map_from_bn = map_generated_bottleneck(decoder_2, np.linspace(-1,1,RESOLUTION), \\\n",
    "        np.linspace(-1,1, RESOLUTION), BOTTLENECK_SIZE, 0, 0, 1, 10)\n",
    "\n",
    "plot_heatmap(reconstructed_map_from_bn[0], \"{}{}_21_label_map_from_bn_0.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[1], \"{}{}_21_label_map_from_bn_1.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[2], \"{}{}_21_label_map_from_bn_2.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[3], \"{}{}_21_label_map_from_bn_3.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[4], \"{}{}_21_label_map_from_bn_4.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[5], \"{}{}_21_label_map_from_bn_5.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[6], \"{}{}_21_label_map_from_bn_6.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[7], \"{}{}_21_label_map_from_bn_7.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[8], \"{}{}_21_label_map_from_bn_8.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n",
    "plot_heatmap(reconstructed_map_from_bn[9], \"{}{}_21_label_map_from_bn_9.png\".format(0,1), \"b0\", \"b1\", -1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbColumn(object):\n",
    "    def __init__(self, mod_along, perturbation, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.perturbation = perturbation\n",
    "        self.dimensions = dimensions\n",
    "        \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        perturbation = self.perturbation\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains random values between 1 - perturbation and 1 + perturbation\n",
    "        # multiplies the input with that matrix to perturb exactly that column of the input uniformly\n",
    "        for key in features.keys():\n",
    "            rand_array = np.random.uniform(1 - perturbation, 1 + perturbation,(BATCH_SIZE, 1))\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            mult_array[:,mod_along] = mult_array[:,mod_along]*rand_array[:,0]\n",
    "            features[key] = features[key] * mult_array\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_mean_of_batched_ds(dataset, key):\n",
    "    # takes all batches and concatenates them back together to get a big list of snapshots\n",
    "    # np.mean is then used to calculate the mean of each column\n",
    "    return np.mean(np.concatenate(np.array([batch[key].numpy() for batch, label in dataset])),axis = 0)\n",
    "\n",
    "class SetMeanColumn(object):\n",
    "    def __init__(self, mod_along, column_mean, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.column_mean = column_mean\n",
    "        self.dimensions = dimensions\n",
    "        \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        column_mean = self.column_mean\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains only zeros\n",
    "        # generates an add_array with only value \"0\" in all columns except for the modified column\n",
    "        # which contains the mean value of the column\n",
    "        # multiplies the input with the mult_array to set the values of the modified column to zero\n",
    "        # adds to the input the add_array to set the values of the modified column to the mean \n",
    "        for key in features.keys():\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            add_array = np.zeros((BATCH_SIZE, dimensions))\n",
    "            mult_array[:,mod_along] = 0.0\n",
    "            add_array[:,mod_along] = column_mean\n",
    "            features[key] = features[key] * mult_array\n",
    "            features[key] = features[key] + add_array\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HIPRColumn(object):\n",
    "    def __init__(self, mod_along, min_value, max_value, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.dimensions = dimensions\n",
    "    \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        min_value = self.min_value\n",
    "        max_value = self.max_value\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains only zeros\n",
    "        # generates an add_array with only value \"0\" in all columns except for the modified column\n",
    "        # which contains random values between min_value and max_value\n",
    "        # multiplies the input with the mult_array to set the values of the modified column to zero\n",
    "        # adds to the input the add_array to set the values of the modified column to random values \n",
    "        for key in features.keys():\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            add_array = np.zeros((BATCH_SIZE, dimensions))\n",
    "            rand_array = np.random.uniform(min_value, max_value,(BATCH_SIZE, 1))\n",
    "            mult_array[:,mod_along] = 0.0\n",
    "            add_array[:,mod_along] = rand_array[:,0]            \n",
    "            features[key] = features[key] * mult_array\n",
    "            features[key] = features[key] + add_array\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_columns_from_batched_ds(dataset, key):\n",
    "    # reconstructs the snapshot list based on the batched dataset that is given\n",
    "    # transposes the dataset to have easy access to the columns\n",
    "    # shuffles each column separately\n",
    "    # returns the array back to its orriginal shape with all columns appearing in new permutations\n",
    "    reconstructed_list = np.concatenate(np.array([batch[key].numpy() for batch, label in dataset]))\n",
    "    reconstructed_list = np.transpose(reconstructed_list)\n",
    "    return reconstructed_list\n",
    "\n",
    "class ShuffleColumn(object):\n",
    "    def __init__(self, mod_along, shuffled_column, dimensions):\n",
    "        self.mod_along = mod_along\n",
    "        self.shuffled_column = shuffled_column\n",
    "        self.dimensions = dimensions\n",
    "    \n",
    "    def __call__(self, features, labels):\n",
    "        mod_along = self.mod_along\n",
    "        shuffled_column = self.shuffled_column\n",
    "        dimensions = self.dimensions\n",
    "        # iterates over all keys of the features (here only 1)\n",
    "        # generates an mult_array with only value \"1\" in all columns except for the modified column\n",
    "        # which contains only zeros\n",
    "        # generates an add_array with only value \"0\" in all columns except for the modified column\n",
    "        # which contains shuffled values from the column\n",
    "        # multiplies the input with the mult_array to set the values of the modified column to zero\n",
    "        # adds to the input the add_array to set the values of the modified column to other values from the column \n",
    "        for key in features.keys():\n",
    "            mult_array = np.ones((BATCH_SIZE, dimensions))\n",
    "            add_array = np.zeros((BATCH_SIZE, dimensions))\n",
    "# the generation of the shuffle array seems quite inefficient so far\n",
    "# maybe pick random slices from the column or find way to pop miltiple items at once\n",
    "            shuffle_array = np.transpose([shuffled_column])\n",
    "# unsure whether this actually works\n",
    "#            shuffle_array = np.transpose([shuffled_column[:BATCH_SIZE]])\n",
    "#            shuffled_column = shuffled_column[BATCH_SIZE:]\n",
    "#            shuffled_column = deepcopy(shuffled_column[BATCH_SIZE:])\n",
    "            mult_array[:,mod_along] = 0.0\n",
    "            add_array[:,mod_along] = shuffle_array[:,0][:BATCH_SIZE]            \n",
    "            features[key] = features[key] * mult_array\n",
    "            features[key] = features[key] + add_array\n",
    "        return features, labels\n",
    "            \n",
    "\n",
    "#print(test_snapshot_list.shape)          \n",
    "#get_shuffled_snapshot_list_from_batched_ds(test_ds, INPUT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def input_importance(mode, mode_var, model, test_ds, dimensions, check_vars, repetitions):\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds_batch, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    # initialization dependent on the mode\n",
    "    if mode == \"perturb\":\n",
    "        perturbation = mode_var\n",
    "    elif mode == \"mean\":\n",
    "        if repetitions > 1:\n",
    "            \"Evaluation occurs on the basis of all batches of size BATCH_SIZE, thereby yielding a reliably result even at only one repetition.\"\n",
    "        mean_value_array = mode_var\n",
    "#        test_ds_list = []\n",
    "    elif mode == \"HIPR\":\n",
    "        min_value = mode_var[0]\n",
    "        max_value = mode_var[1]\n",
    "    elif mode == \"shuffle\":\n",
    "        column_array = mode_var\n",
    "        \n",
    "    print(\"Mode: {}\".format(mode))\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            # mapping of the dataset depending on the code\n",
    "            if mode == \"perturb\":\n",
    "                mod_test_ds = test_ds_batch.map(PerturbColumn(variable_nr, perturbation, dimensions), CORES_USED)\n",
    "                new_columns = get_columns_from_batched_ds(mod_test_ds, INPUT_NAME)\n",
    "                print(new_columns[variable_nr][:5]) #testing\n",
    "                print(new_columns[variable_nr][64:69]) #testing\n",
    "                #             mod_test_ds = tf.map_fn(PerturbColumn(variable_nr, perturbation, dimensions), test_ds_batch)\n",
    "            elif mode == \"mean\":\n",
    "                mod_test_ds = test_ds.map(SetMeanColumn(variable_nr, mean_value_array[variable_nr], dimensions), CORES_USED).batch(BATCH_SIZE, drop_remainder=DROP_REMAINDER)\n",
    "#                    test_ds_list.append(mod_test_ds)\n",
    "            elif mode == \"HIPR\":\n",
    "                mod_test_ds = test_ds.map(HIPRColumn(variable_nr, min_value, max_value, dimensions), CORES_USED).batch(BATCH_SIZE, drop_remainder=DROP_REMAINDER)\n",
    "                new_columns = get_columns_from_batched_ds(mod_test_ds, INPUT_NAME)\n",
    "                print(new_columns[variable_nr][:5]) #testing\n",
    "                print(new_columns[variable_nr][64:69]) #testing\n",
    "            elif mode == \"shuffle\":\n",
    "                mod_test_ds = test_ds_batch.map(ShuffleColumn(variable_nr, column_array[variable_nr], dimensions), CORES_USED)\n",
    "                new_columns = get_columns_from_batched_ds(mod_test_ds, INPUT_NAME)\n",
    "                print(new_columns[variable_nr][:5]) #testing\n",
    "                print(new_columns[variable_nr][64:69]) #testing\n",
    "            # calculate the different losses with the new dataset\n",
    "            t_loss, l_loss, r_loss = model.evaluate(mod_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,r_loss-orig_r_loss))\n",
    "        # average over the loss lists\n",
    "        # negative increases of loss are set to zero\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))                \n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "\n",
    "def plot_input_importance(loss_list, loss_type, name, perturbation):\n",
    "    variable_nr = len(loss_list[0])\n",
    "    plt.bar(range(variable_nr),loss_list[loss_type])\n",
    "    if perturbation == None:\n",
    "        plt.savefig(\"{}_{}.png\".format(name,loss_type))        \n",
    "    else:\n",
    "        plt.savefig(\"{}_{}_pert_{}.png\".format(name,loss_type,perturbation))\n",
    "    plt.close()\n",
    "    \n",
    "#perturbed_loss_list = input_importance(\"perturb\", 0.5, autoencoder, test_ds, DIMENSIONS, range(3), 1)\n",
    "#plot_input_importance(perturbed_loss_list,1,\"Input_perturbation\",\"0.5\")\n",
    "#mean_loss_list = input_importance(\"mean\", get_column_mean_of_batched_ds(test_ds, INPUT_NAME), autoencoder, test_ds, DIMENSIONS, range(3), 1)\n",
    "#plot_input_importance(mean_loss_list,1,\"Stepwise\", None)\n",
    "#hipr_loss_list = input_importance(\"HIPR\", [-0.9,0.9], autoencoder, test_ds, DIMENSIONS, range(3), 3)\n",
    "#plot_input_importance(hipr_loss_list,1,\"HIPR\", None)\n",
    "shuffle_loss_list = input_importance(\"shuffle\", get_columns_from_batched_ds(test_ds_batch, INPUT_NAME), autoencoder, test_ds, DIMENSIONS, range(1), 1)\n",
    "plot_input_importance(shuffle_loss_list,1,\"Shuffle\", None)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_shuffled_columns_from_batched_ds(dataset, key):\n",
    "    # reconstructs the snapshot list based on the batched dataset that is given\n",
    "    # transposes the dataset to have easy access to the columns\n",
    "    # shuffles each column separately\n",
    "    # returns the array back to its orriginal shape with all columns appearing in new permutations\n",
    "    reconstructed_list = np.concatenate(np.array([batch[key].numpy() for batch, label in dataset]))\n",
    "    reconstructed_list = np.transpose(reconstructed_list)\n",
    "    for column_nr in range(len(reconstructed_list)):\n",
    "        reconstructed_list[column_nr] = shuffle(reconstructed_list[column_nr])\n",
    "    reconstructed_list\n",
    "    return reconstructed_list\n",
    "\n",
    "# modify original numpy arrays, generate new datasets and use that for the comparison \n",
    "def input_perturbation_efficiently(model, test_ds, snapshot_list, snapshot_label_list, perturbation, check_vars, repetitions):\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds, verbose=0, steps= 1000)\n",
    "    meta_loss_list = []\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            #print(snapshot_list)\n",
    "            perturbed_snapshot_list = snapshot_list.copy()\n",
    "            # generates random perturbation scaling array, with values uniformly distributed around 1 \n",
    "            # ranging from 1 - perturbation to 1 + perturbation\n",
    "            rand_array = (np.random.rand(len(snapshot_list), 1)-0.5)*(2*perturbation)+1\n",
    "            # multiply corresponding column of the dataset with perturbation scaling array\n",
    "            perturbed_snapshot_list[:,variable_nr] = perturbed_snapshot_list[:,variable_nr]*rand_array[:,0]\n",
    "            # make a new perturbed Dataset to feed into the previously trained model\n",
    "            perturbed_ds = tf.data.Dataset.from_tensor_slices(({INPUT_NAME: perturbed_snapshot_list},\n",
    "                                            {OUTPUT_NAME_1:snapshot_label_list, \n",
    "                                             OUTPUT_NAME_2:snapshot_list})).shuffle(DATASET_SIZE)\n",
    "            perturbed_test_ds = perturbed_ds.skip(TRAIN_SIZE).batch(BATCH_SIZE)\n",
    "            # calculate the different losses with the new dataset\n",
    "            pert_t_loss, pert_l_loss, pert_r_loss = model.evaluate(perturbed_test_ds, verbose=0, steps = 1000)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,pert_t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,pert_l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,pert_r_loss-orig_r_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "    \n",
    "    \n",
    "def input_perturbation_most_efficient(model, test_ds, perturbation, check_vars, repetitions):\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            perturbed_test_ds = test_ds.map(PerturbDataset(variable_nr, perturbation))\n",
    "            # calculate the different losses with the new dataset\n",
    "            pert_t_loss, pert_l_loss, pert_r_loss = model.evaluate(perturbed_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,pert_t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,pert_l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,pert_r_loss-orig_r_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    return np.array(sum(meta_loss_list)/repetitions)\n",
    "    \n",
    "def improved_stepwise(model, test_ds, check_vars, repetitions):\n",
    "    if repetitions > 1:\n",
    "        \"Evaluation occurs on the basis of all batches of size BATCH_SIZE, thereby yielding a reliably result even at only one repetition.\"\n",
    "    orig_t_loss, orig_l_loss, orig_r_loss = model.evaluate(test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "    meta_loss_list = []\n",
    "    mean_value_array = get_column_mean_of_batched_ds(test_ds)\n",
    "    for repetition in range(repetitions):\n",
    "        print(\"Repetition {}.\".format(repetition+1))\n",
    "        loss_list = [[],[],[]]\n",
    "        test_ds_list = []\n",
    "        for variable_nr in check_vars:\n",
    "            print(\"\\tPerturbing variable {}.\".format(variable_nr))\n",
    "            m_col_test_ds = test_ds.map(TakeColumnMean(variable_nr, mean_value_array[variable_nr],DIMENSIONS))\n",
    "            test_ds_list.append(m_col_test_ds)\n",
    "            # calculate the different losses with the new dataset\n",
    "            m_col_t_loss, m_col_l_loss, m_col_r_loss = model.evaluate(m_col_test_ds, verbose=0, steps = STEP_NUMBER)\n",
    "            # append the losses to a collective list for later comparison\n",
    "            loss_list[0].append(max(0,m_col_t_loss-orig_t_loss))\n",
    "            loss_list[1].append(max(0,m_col_l_loss-orig_l_loss))\n",
    "            loss_list[2].append(max(0,m_col_r_loss-orig_r_loss))\n",
    "        for row_nr in range(len(loss_list)):\n",
    "            full_loss = sum(loss_list[row_nr])\n",
    "            for col_nr in range(len(loss_list[row_nr])):\n",
    "                if full_loss > 0:\n",
    "                    loss_list[row_nr][col_nr] = loss_list[row_nr][col_nr]/full_loss\n",
    "                else:\n",
    "                    loss_list[row_nr][col_nr] = 0\n",
    "        meta_loss_list.append(np.array(loss_list))\n",
    "    return np.array(sum(meta_loss_list)/repetitions), test_ds_list   \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\"\"\"encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(3)(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
    "x = keras.layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = keras.layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = keras.layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = keras.layers.UpSampling2D(3)(x)\n",
    "x = keras.layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = keras.layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
    "autoencoder.summary()\"\"\"\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
