{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpathsampling as ops\n",
    "import openpathsampling.engines.toy as toys\n",
    "from potentials import DoublewellPotential, ZPotential\n",
    "from toyPlot import ToyPlot\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PES_type = \"ZP\"\n",
    "assert PES_type == \"DW\" or PES_type == \"ZP\", \\\n",
    "    \"PES_type must be chosen to match either 'DW' or 'ZP'\"\n",
    "simulation_length = 1000000\n",
    "additional_dim_generator = \"HO\"\n",
    "assert additional_dim_generator == \"HO\" or additional_dim_generator == \"UR\", \\\n",
    "    \"additional_dim_generator must be chosen to match either 'HO' or 'UR'\"\n",
    "additional_dimensions = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_doublewell_potential():\n",
    "    pes = DoublewellPotential()\n",
    "    plot = ToyPlot((-1.1, 1.1), (-1.1, 1.1))\n",
    "    plot.contour_range = np.arange(-1.0, 1.5, 0.1)\n",
    "    plot.add_pes(pes)\n",
    "    return plot, pes\n",
    "\n",
    "def prepare_Z_potential():\n",
    "    pes = ZPotential()\n",
    "    plot = ToyPlot((-20.1, 20.1), (-20.1, 20.1))\n",
    "    plot.contour_range = np.arange(-1.5, 7.5, 0.5)\n",
    "    plot.add_pes(pes)\n",
    "    return plot, pes\n",
    "\n",
    "if PES_type == \"DW\":\n",
    "    plot, pes = prepare_doublewell_potential()\n",
    "elif PES_type == \"ZP\":\n",
    "    plot, pes = prepare_Z_potential()\n",
    "\n",
    "plot.plot()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = toys.Topology(n_spatial=2, masses=[1.0, 1.0], pes=pes)\n",
    "\n",
    "if PES_type == \"DW\":\n",
    "    integrator_params = {\"dt\": 0.02, \"temperature\": 0.1, \"gamma\": 2.5}\n",
    "elif PES_type == \"ZP\":\n",
    "    integrator_params = {\"dt\": 0.2, \"temperature\": 1.0, \"gamma\": 1.0}\n",
    "\n",
    "toy_engine = toys.Engine(\n",
    "    {'integ': toys.LangevinBAOABIntegrator(**integrator_params),\n",
    "     'n_frames_max': 50000, 'n_steps_per_frame': 1}, topology)\n",
    "toy_engine.current_snapshot = toys.Snapshot(\n",
    "    coordinates=np.array([[0.0, 0.0]]),\n",
    "    velocities=np.array([[0.0, 0.0]]),\n",
    "    engine=toy_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle(snapshot, center):\n",
    "    import math\n",
    "    return math.sqrt(\n",
    "        (snapshot.xyz[0][0] - center[0])**2\n",
    "        + (snapshot.xyz[0][1] - center[1])**2)\n",
    "\n",
    "def disk(snapshot, center):\n",
    "    import math\n",
    "    return math.sqrt(\n",
    "        (snapshot.xyz[0][0]-center[0])**2/16 \n",
    "        + (snapshot.xyz[0][1]-center[1])**2)\n",
    "\n",
    "if PES_type == \"DW\":\n",
    "    opA = ops.CoordinateFunctionCV(\n",
    "        name=\"opA\", f=circle, center=[-0.5, 0.0])\n",
    "    stateA = ops.CVDefinedVolume(opA, 0.0, 0.2).named(\"A\")\n",
    "    opB = ops.CoordinateFunctionCV(\n",
    "        name=\"opB\", f=circle, center=[0.5, 0.0])\n",
    "    stateB = ops.CVDefinedVolume(opB, 0.0, 0.2).named(\"B\")\n",
    "elif PES_type == \"ZP\":\n",
    "    opA = ops.CoordinateFunctionCV(\n",
    "        name=\"opA\", f=disk, center=[-7.2, -5.1])\n",
    "    stateA = ops.CVDefinedVolume(opA, 0.0, 0.25).named(\"A\")\n",
    "    opB = ops.CoordinateFunctionCV(\n",
    "        name=\"opB\", f=disk, center=[7.2, 5.1])\n",
    "    stateB = ops.CVDefinedVolume(opB, 0.0, 0.25).named(\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_trajectory = \\\n",
    "    toy_engine.generate_n_frames(n_frames = simulation_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ens_1InA = ops.IntersectionEnsemble(\n",
    "    ops.AllInXEnsemble(stateA), ops.LengthEnsemble(1))\n",
    "Ens_1InB = ops.IntersectionEnsemble(\n",
    "    ops.AllInXEnsemble(stateB), ops.LengthEnsemble(1))\n",
    "Ens_NotInAB = ops.IntersectionEnsemble(\n",
    "    ops.AllOutXEnsemble(stateA), ops.AllOutXEnsemble(stateB))\n",
    "\n",
    "print(\"Starting: AB\")\n",
    "AB_network = ops.SequentialEnsemble((Ens_1InA,Ens_NotInAB,Ens_1InB))\n",
    "subtrajectories_AB = AB_network.split(long_trajectory)\n",
    "print(len(subtrajectories_AB))\n",
    "\n",
    "print(\"Starting: BA\")\n",
    "BA_network = ops.SequentialEnsemble((Ens_1InB,Ens_NotInAB,Ens_1InA))\n",
    "subtrajectories_BA = BA_network.split(long_trajectory)\n",
    "print(len(subtrajectories_BA))\n",
    "\n",
    "print(\"Starting: AA\")\n",
    "AA_network = ops.SequentialEnsemble((Ens_1InA,Ens_NotInAB,Ens_1InA))\n",
    "subtrajectories_AA = AA_network.split(long_trajectory)\n",
    "print(len(subtrajectories_AA))\n",
    "\n",
    "print(\"Starting: BB\")\n",
    "BB_network = ops.SequentialEnsemble((Ens_1InB,Ens_NotInAB,Ens_1InB))\n",
    "subtrajectories_BB = BB_network.split(long_trajectory)\n",
    "print(len(subtrajectories_BB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot(subtrajectories_AB)\n",
    "plot.plot(subtrajectories_BA)\n",
    "plot.plot(subtrajectories_AA)\n",
    "plot.plot(subtrajectories_BB)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_in = {}\n",
    "steps_in[\"AA\"] = sum([len(trajectory) for trajectory in subtrajectories_AA])\n",
    "steps_in[\"AB\"] = sum([len(trajectory) for trajectory in subtrajectories_AB])\n",
    "steps_in[\"BA\"] = sum([len(trajectory) for trajectory in subtrajectories_BA])\n",
    "steps_in[\"BB\"] = sum([len(trajectory) for trajectory in subtrajectories_BB])\n",
    "steps_in[\"any path\"] = sum([value for key, value in steps_in.items()])\n",
    "percentage_out_of_states = 100 * steps_in[\"any path\"] / simulation_length\n",
    "print(f\"Simulation of {simulation_length} steps was decomposed into:\\n\"\n",
    "      + f\"{steps_in['any path']} steps ({percentage_out_of_states}%) spend\"\n",
    "      + \" in total outside of the stable states.\")\n",
    "print(f\"{steps_in['AA']} steps spend in AA trajectories.\")\n",
    "print(f\"{steps_in['AB']} steps spend in AB trajectories.\")\n",
    "print(f\"{steps_in['BA']} steps spend in BA trajectories.\")\n",
    "print(f\"{steps_in['BB']} steps spend in BB trajectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_array_AA = np.array([np.array([xy_position[0] \\\n",
    "    for xy_position in trajectory.xyz]) \\\n",
    "    for trajectory in subtrajectories_AA])\n",
    "total_array_AB = np.array([np.array([xy_position[0] \\\n",
    "    for xy_position in trajectory.xyz]) \\\n",
    "    for trajectory in subtrajectories_AB])\n",
    "total_array_BA = np.array([np.array([xy_position[0] \\\n",
    "    for xy_position in trajectory.xyz]) \\\n",
    "    for trajectory in subtrajectories_BA])\n",
    "total_array_BB = np.array([np.array([xy_position[0] \\\n",
    "    for xy_position in trajectory.xyz]) \\\n",
    "    for trajectory in subtrajectories_BB])\n",
    "\n",
    "trajectory_list = np.array(\n",
    "    [trajectory for trajectory in total_array_AA]\n",
    "    + [trajectory for trajectory in total_array_AB]\n",
    "    + [trajectory for trajectory in total_array_BA]\n",
    "    + [trajectory for trajectory in total_array_BB])\n",
    "\n",
    "trajectory_label_list = np.array(\n",
    "    [\"AA\" for trajectory in total_array_AA]\n",
    "    + [\"AB\" for trajectory in total_array_AB]\n",
    "    + [\"BA\" for trajectory in total_array_BA]\n",
    "    + [\"BB\" for trajectory in total_array_BB])\n",
    "\n",
    "print(trajectory_list.shape)\n",
    "print(trajectory_label_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_additional_dimensions_via_harmonic_oscillator(\n",
    "        additional_dims, steps_in_any_path):\n",
    "    pes = toys.HarmonicOscillator(\n",
    "        additional_dims * [1.0], additional_dims * [1.0], additional_dims * [0.0])\n",
    "    topology = toys.Topology(\n",
    "        n_spatial=additional_dims, masses=additional_dims *[1.0], pes=pes)\n",
    "    toy_engine = toys.Engine(\n",
    "        {'integ': toys.LangevinBAOABIntegrator(**integrator_params),\n",
    "         'n_frames_max': 50000, 'n_steps_per_frame': 1}, topology)\n",
    "    template = toys.Snapshot(\n",
    "        coordinates=np.array([additional_dims * [0.0]]),\n",
    "        velocities=np.array([additional_dims * [0.0]]),\n",
    "        engine=toy_engine)\n",
    "    toy_engine.current_snapshot = template\n",
    "    trajectory = toy_engine.generate_n_frames(n_frames = steps_in_any_path)\n",
    "    return trajectory.xyz[:,0]\n",
    "\n",
    "def generate_additional_dimensions_via_uniform_random(\n",
    "        additional_dims, steps_in_any_path):\n",
    "    return np.array([[(random.random()-0.5)*2 \n",
    "                    for i in range(additional_dims)]\n",
    "                    for j in range(steps_in_any_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if additional_dim_generator == \"HO\":\n",
    "    additional_dimension_entries = \\\n",
    "        generate_additional_dimensions_via_harmonic_oscillator(\n",
    "            additional_dimensions, steps_in[\"any path\"])\n",
    "elif additional_dim_generator == \"UR\":\n",
    "    additional_dimension_entries = \\\n",
    "        generate_additional_dimensions_via_uniform_random(\n",
    "            additional_dimensions, steps_in[\"any path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_path_trajectories_with_additional_dimensions(\n",
    "        trajectory_list, additional_dimension_entries):\n",
    "    full_trajectory_list = []\n",
    "    traj_start = 0\n",
    "    for trajectory in trajectory_list:\n",
    "        traj_end = traj_start + len(trajectory)\n",
    "        add_trajectory = additional_dimension_entries[traj_start:traj_end]\n",
    "        full_trajectory_list.append(\n",
    "            np.concatenate((trajectory, add_trajectory),axis =1))\n",
    "        traj_start = traj_end\n",
    "    return np.array(full_trajectory_list)\n",
    "\n",
    "extended_trajectory_list = extend_path_trajectories_with_additional_dimensions(\n",
    "        trajectory_list, additional_dimension_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = str(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "pickle.dump(\n",
    "    extended_trajectory_list,\n",
    "    open(f\"{PES_type}_{time_stamp}_paths.p\", \"wb\"))\n",
    "pickle.dump(\n",
    "    trajectory_label_list,\n",
    "    open(f\"{PES_type}_{time_stamp}_labels.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
